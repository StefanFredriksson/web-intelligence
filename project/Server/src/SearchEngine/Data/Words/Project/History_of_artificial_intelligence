History of artificial intelligence See also Timeline of artificial intelligence and Progress in artificial intelligence Artificial intelligence Major goals Knowledge reasoning Planning Machine learning Natural language processing Computer vision Robotics Artificial general intelligence Approaches Symbolic Deep learning Bayesian networks Evolutionary algorithms Philosophy Ethics Existential risk Turing test Chinese room Control problem Friendly AI History Timeline Progress AI winter Technology Applications Projects Programming languages Glossary Glossary v t e History of computing Hardware Hardware before 1960 Hardware 1960s to present Software Software Unix Free software and opensource software Computer science Artificial intelligence Compiler construction Computer science Operating systems Programming languages Prominent pioneers Software engineering Modern concepts Generalpurpose CPUs Graphical user interface Internet Laptops Personal computers Video games World Wide Web By country Bulgaria Poland Romania Soviet Bloc Soviet Union Yugoslavia Timeline of computing before 1950 19501979 19801989 19901999 20002009 20102019 more timelines Glossary of computer science Category v t e The history of Artificial Intelligence AI began in antiquity with myths stories and rumors of artificial beings endowed with intelligence or consciousness by master craftsmen The seeds of modern AI were planted by classical philosophers who attempted to describe the process of human thinking as the mechanical manipulation of symbols This work culminated in the invention of the programmable digital computer in the 1940s a machine based on the abstract essence of mathematical reasoning This device and the ideas behind it inspired a handful of scientists to begin seriously discussing the possibility of building an electronic brain The field of AI research was founded at a workshop held on the campus of Dartmouth College during the summer of 1956 1 Those who attended would become the leaders of AI research for decades Many of them predicted that a machine as intelligent as a human being would exist in no more than a generation and they were given millions of dollars to make this vision come true Eventually it became obvious that they had grossly underestimated the difficulty of the project In 1973 in response to the criticism from James Lighthill and ongoing pressure from congress the US and British Governments stopped funding undirected research into artificial intelligence and the difficult years that followed would later be known as an AI winter Seven years later a visionary initiative by the Japanese Government inspired governments and industry to provide AI with billions of dollars but by the late 80s the investors became disillusioned by the absence of the needed computer power hardware and withdrew funding again Investment and interest in AI boomed in the first decades of the 21st century when machine learning was successfully applied to many problems in academia and industry due to new methods the application of powerful computer hardware and the collection of immense data sets Contents 1 AI in myth fiction and speculation 2 Automatons 3 Formal reasoning 4 Computer science 5 The birth of artificial intelligence 19521956 51 Cybernetics and early neural networks 52 Turings test 53 Game AI 54 Symbolic reasoning and the Logic Theorist 55 Dartmouth Conference 1956 the birth of AI 6 The golden years 19561974 61 The work 611 Reasoning as search 612 Natural language 613 Microworlds 62 The optimism 63 The money 64 Robotics 7 The first AI winter 19741980 71 The problems 72 The end of funding 73 Critiques from across campus 74 Perceptrons and the attack on connectionism 75 Utilizing logic and symbolic reasoning 76 Another approach frames and scripts 8 Boom 19801987 81 The rise of expert systems 82 The knowledge revolution 83 The money returns the Fifth Generation project 84 The revival of connectionism 9 Bust the second AI winter 19871993 91 A New and Different AI winter 92 The importance of having a body nouvelle AI and embodied reason 10 AI 19932011 101 Milestones and Moores law 102 Intelligent agents 103 Implementation of Rigor 104 AI behind the scenes 105 Predictions 11 Deep learning big data and artificial general intelligence 2011present 111 Deep learning 112 Big Data 113 Artificial general intelligence 12 See also 13 Notes 14 References AI in myth fiction and speculation edit Main article Artificial intelligence in fiction Mechanical men and artificial beings appear in Greek myths such as the golden robots of Hephaestus and Pygmalions Galatea 2 In the Middle Ages there were rumors of secret mystical or alchemical means of placing mind into matter such as Jābir ibn Hayyān s Takwin Paracelsus homunculus and Rabbi Judah Loew s Golem 3 By the 19th century ideas about artificial men and thinking machines were developed in fiction as in Mary Shelley s Frankenstein or Karel Čapek s RUR Rossums Universal Robots 4 and speculation such as Samuel Butler s Darwin among the Machines 5 AI has continued to be an important element of science fiction into the present Automatons edit Main article Automaton AlJazari s programmable automata 1206 CE Realistic humanoid automatons were built by craftsman from every civilization including Yan Shi 6 Hero of Alexandria 7 AlJazari 8 Pierre JaquetDroz and Wolfgang von Kempelen 9 The oldest known automatons were the sacred statues of ancient Egypt and Greece The faithful believed that craftsman had imbued these figures with very real minds capable of wisdom and emotion Hermes Trismegistus wrote that by discovering the true nature of the gods man has been able to reproduce it 10 11 Formal reasoning edit Artificial intelligence is based on the assumption that the process of human thought can be mechanized The study of mechanicalor formalreasoning has a long history Chinese Indian and Greek philosophers all developed structured methods of formal deduction in the first millennium BCE Their ideas were developed over the centuries by philosophers such as Aristotle who gave a formal analysis of the syllogism Euclid whose Elements was a model of formal reasoning alKhwārizmī who developed algebra and gave his name to algorithm and European scholastic philosophers such as William of Ockham and Duns Scotus 12 Spanish philosopher Ramon Llull 12321315 developed several logical machines devoted to the production of knowledge by logical means 13 Llull described his machines as mechanical entities that could combine basic and undeniable truths by simple logical operations produced by the machine by mechanical meanings in such ways as to produce all the possible knowledge 14 Llulls work had a great influence on Gottfried Leibniz who redeveloped his ideas 15 Gottfried Leibniz who speculated that human reason could be reduced to mechanical calculation In the 17th century Leibniz Thomas Hobbes and René Descartes explored the possibility that all rational thought could be made as systematic as algebra or geometry 16 Hobbes famously wrote in Leviathan reason is nothing but reckoning 17 Leibniz envisioned a universal language of reasoning his characteristica universalis which would reduce argumentation to calculation so that there would be no more need of disputation between two philosophers than between two accountants For it would suffice to take their pencils in hand down to their slates and to say each other with a friend as witness if they liked Let us calculate 18 These philosophers had begun to articulate the physical symbol system hypothesis that would become the guiding faith of AI research In the 20th century the study of mathematical logic provided the essential breakthrough that made artificial intelligence seem plausible The foundations had been set by such works as Boole s The Laws of Thought and Frege s Begriffsschrift Building on Frege s system Russell and Whitehead presented a formal treatment of the foundations of mathematics in their masterpiece the Principia Mathematica in 1913 Inspired by Russell s success David Hilbert challenged mathematicians of the 1920s and 30s to answer this fundamental question can all of mathematical reasoning be formalized 12 His question was answered by Gödel s incompleteness proof Turing s machine and Church s Lambda calculus 12 19 US Army photo of the ENIAC at the Moore School of Electrical Engineering 20 Their answer was surprising in two ways First they proved that there were in fact limits to what mathematical logic could accomplish But second and more important for AI their work suggested that within these limits any form of mathematical reasoning could be mechanized The ChurchTuring thesis implied that a mechanical device shuffling symbols as simple as 0 and 1 could imitate any conceivable process of mathematical deduction The key insight was the Turing machine a simple theoretical construct that captured the essence of abstract symbol manipulation This invention would inspire a handful of scientists to begin discussing the possibility of thinking machines 12 21 Computer science edit Main articles history of computer hardware and history of computer science Calculating machines were built in antiquity and improved throughout history by many mathematicians including once again philosopher Gottfried Leibniz In the early 19th century Charles Babbage designed a programmable computer the Analytical Engine although it was never built Ada Lovelace speculated that the machine might compose elaborate and scientific pieces of music of any degree of complexity or extent 22 She is often credited as the first programmer because of a set of notes she wrote that completely detail a method for calculating Bernoulli numbers with the Engine The first modern computers were the massive code breaking machines of the Second World War such as Z3 ENIAC and Colossus The latter two of these machines were based on the theoretical foundation laid by Alan Turing 23 and developed by John von Neumann 24 The birth of artificial intelligence 19521956 edit The IBM 702 a computer used by the first generation of AI researchers In the 1940s and 50s a handful of scientists from a variety of fields mathematics psychology engineering economics and political science began to discuss the possibility of creating an artificial brain The field of artificial intelligence research was founded as an academic discipline in 1956 Cybernetics and early neural networks edit The earliest research into thinking machines was inspired by a confluence of ideas that became prevalent in the late 1930s 1940s and early 1950s Recent research in neurology had shown that the brain was an electrical network of neurons that fired in allornothing pulses Norbert Wiener s cybernetics described control and stability in electrical networks Claude Shannon s information theory described digital signals ie allornothing signals Alan Turing s theory of computation showed that any form of computation could be described digitally The close relationship between these ideas suggested that it might be possible to construct an electronic brain 25 Examples of work in this vein includes robots such as W Grey Walter s turtles and the Johns Hopkins Beast These machines did not use computers digital electronics or symbolic reasoning they were controlled entirely by analog circuitry 26 Walter Pitts and Warren McCulloch analyzed networks of idealized artificial neurons and showed how they might perform simple logical functions They were the first to describe what later researchers would call a neural network 27 One of the students inspired by Pitts and McCulloch was a young Marvin Minsky then a 24yearold graduate student In 1951 with Dean Edmonds he built the first neural net machine the SNARC 28 Minsky was to become one of the most important leaders and innovators in AI for the next 50 years Turings test edit In 1950 Alan Turing published a landmark paper in which he speculated about the possibility of creating machines that think 29 He noted that thinking is difficult to define and devised his famous Turing Test If a machine could carry on a conversation over a teleprinter that was indistinguishable from a conversation with a human being then it was reasonable to say that the machine was thinking This simplified version of the problem allowed Turing to argue convincingly that a thinking machine was at least plausible and the paper answered all the most common objections to the proposition 30 The Turing Test was the first serious proposal in the philosophy of artificial intelligence Game AI edit In 1951 using the Ferranti Mark 1 machine of the University of Manchester Christopher Strachey wrote a checkers program and Dietrich Prinz wrote one for chess 31 Arthur Samuel s checkers program developed in the middle 50s and early 60s eventually achieved sufficient skill to challenge a respectable amateur 32 Game AI would continue to be used as a measure of progress in AI throughout its history Symbolic reasoning and the Logic Theorist edit When access to digital computers became possible in the middle fifties a few scientists instinctively recognized that a machine that could manipulate numbers could also manipulate symbols and that the manipulation of symbols could well be the essence of human thought This was a new approach to creating thinking machines 33 In 1955 Allen Newell and future Nobel Laureate Herbert A Simon created the Logic Theorist with help from J C Shaw The program would eventually prove 38 of the first 52 theorems in Russell and Whiteheads Principia Mathematica and find new and more elegant proofs for some 34 Simon said that they had solved the venerable mindbody problem explaining how a system composed of matter can have the properties of mind 35 This was an early statement of the philosophical position John Searle would later call Strong AI that machines can contain minds just as human bodies do 36 Dartmouth Conference 1956 the birth of AI edit The Dartmouth Conference of 1956 37 was organized by Marvin Minsky John McCarthy and two senior scientists Claude Shannon and Nathan Rochester of IBM The proposal for the conference included this assertion every aspect of learning or any other feature of intelligence can be so precisely described that a machine can be made to simulate it 38 The participants included Ray Solomonoff Oliver Selfridge Trenchard More Arthur Samuel Allen Newell and Herbert A Simon all of whom would create important programs during the first decades of AI research 39 At the conference Newell and Simon debuted the Logic Theorist and McCarthy persuaded the attendees to accept Artificial Intelligence as the name of the field 40 The 1956 Dartmouth conference was the moment that AI gained its name its mission its first success and its major players and is widely considered the birth of AI 41 The term Artificial Intelligence was chosen by McCarthy to avoid associations with cybernetics and connections with the influential cyberneticist Norbert Wiener 42 The golden years 19561974 edit The years after the Dartmouth conference were an era of discovery of sprinting across new ground The programs that were developed during this time were to most people simply astonishing 43 computers were solving algebra word problems proving theorems in geometry and learning to speak English Few at the time would have believed that such intelligent behavior by machines was possible at all 44 Researchers expressed an intense optimism in private and in print predicting that a fully intelligent machine would be built in less than 20 years 45 Government agencies like DARPA poured money into the new field 46 The work edit There were many successful programs and new directions in the late 50s and 1960s Among the most influential were these Reasoning as search edit Many early AI programs used the same basic algorithm To achieve some goal like winning a game or proving a theorem they proceeded step by step towards it by making a move or a deduction as if searching through a maze backtracking whenever they reached a dead end This paradigm was called reasoning as search 47 The principal difficulty was that for many problems the number of possible paths through the maze was simply astronomical a situation known as a combinatorial explosion Researchers would reduce the search space by using heuristics or rules of thumb that would eliminate those paths that were unlikely to lead to a solution 48 Newell and Simon tried to capture a general version of this algorithm in a program called the General Problem Solver 49 Other searching programs were able to accomplish impressive tasks like solving problems in geometry and algebra such as Herbert Gelernter s Geometry Theorem Prover 1958 and SAINT written by Minskys student James Slagle 1961 50 Other programs searched through goals and subgoals to plan actions like the STRIPS system developed at Stanford to control the behavior of their robot Shakey 51 An example of a semantic network Natural language edit An important goal of AI research is to allow computers to communicate in natural languages like English An early success was Daniel Bobrow s program STUDENT which could solve high school algebra word problems 52 A semantic net represents concepts eg housedoor as nodes and relations among concepts eg hasa as links between the nodes The first AI program to use a semantic net was written by Ross Quillian 53 and the most successful and controversial version was Roger Schank s Conceptual dependency theory 54 Joseph Weizenbaum s ELIZA could carry out conversations that were so realistic that users occasionally were fooled into thinking they were communicating with a human being and not a program But in fact ELIZA had no idea what she was talking about She simply gave a canned response or repeated back what was said to her rephrasing her response with a few grammar rules ELIZA was the first chatterbot 55 Microworlds edit In the late 60s Marvin Minsky and Seymour Papert of the MIT AI Laboratory proposed that AI research should focus on artificially simple situations known as microworlds They pointed out that in successful sciences like physics basic principles were often best understood using simplified models like frictionless planes or perfectly rigid bodies Much of the research focused on a blocks world which consists of colored blocks of various shapes and sizes arrayed on a flat surface 56 This paradigm led to innovative work in machine vision by Gerald Sussman who led the team Adolfo Guzman David Waltz who invented constraint propagation and especially Patrick Winston At the same time Minsky and Papert built a robot arm that could stack blocks bringing the blocks world to life The crowning achievement of the microworld program was Terry Winograd s SHRDLU It could communicate in ordinary English sentences plan operations and execute them 57 The optimism edit The first generation of AI researchers made these predictions about their work 1958 H A Simon and Allen Newell within ten years a digital computer will be the worlds chess champion and within ten years a digital computer will discover and prove an important new mathematical theorem 58 1965 H A Simon machines will be capable within twenty years of doing any work a man can do 59 1967 Marvin Minsky Within a generation the problem of creating artificial intelligence will substantially be solved 60 1970 Marvin Minsky in Life Magazine In from three to eight years we will have a machine with the general intelligence of an average human being 61 The money edit In June 1963 MIT received a 22 million grant from the newly created Advanced Research Projects Agency later known as DARPA The money was used to fund project MAC which subsumed the AI Group founded by Minsky and McCarthy five years earlier DARPA continued to provide three million dollars a year until the 70s 62 DARPA made similar grants to Newell and Simons program at CMU and to the Stanford AI Project founded by John McCarthy in 1963 63 Another important AI laboratory was established at Edinburgh University by Donald Michie in 1965 64 These four institutions would continue to be the main centers of AI research and funding in academia for many years 65 The money was proffered with few strings attached J C R Licklider then the director of ARPA believed that his organization should fund people not projects and allowed researchers to pursue whatever directions might interest them 66 This created a freewheeling atmosphere at MIT that gave birth to the hacker culture 67 but this hands off approach would not last Robotics edit In Japan Waseda University initiated the WABOT project in 1967 and in 1972 completed the WABOT1 the worlds first fullscale intelligent humanoid robot 68 69 or android Its limb control system allowed it to walk with the lower limbs and to grip and transport objects with hands using tactile sensors Its vision system allowed it to measure distances and directions to objects using external receptors artificial eyes and ears And its conversation system allowed it to communicate with a person in Japanese with an artificial mouth 70 71 72 The first AI winter 19741980 edit In the 1970s AI was subject to critiques and financial setbacks AI researchers had failed to appreciate the difficulty of the problems they faced Their tremendous optimism had raised expectations impossibly high and when the promised results failed to materialize funding for AI disappeared 73 At the same time the field of connectionism or neural nets was shut down almost completely for 10 years by Marvin Minsky s devastating criticism of perceptrons 74 Despite the difficulties with public perception of AI in the late 70s new ideas were explored in logic programming commonsense reasoning and many other areas 75 The problems edit In the early seventies the capabilities of AI programs were limited Even the most impressive could only handle trivial versions of the problems they were supposed to solve all the programs were in some sense toys 76 AI researchers had begun to run into several fundamental limits that could not be overcome in the 1970s Although some of these limits would be conquered in later decades others still stymie the field to this day 77 Limited computer power There was not enough memory or processing speed to accomplish anything truly useful For example Ross Quillian s successful work on natural language was demonstrated with a vocabulary of only twenty words because that was all that would fit in memory 78 Hans Moravec argued in 1976 that computers were still millions of times too weak to exhibit intelligence He suggested an analogy artificial intelligence requires computer power in the same way that aircraft require horsepower Below a certain threshold its impossible but as power increases eventually it could become easy 79 With regard to computer vision Moravec estimated that simply matching the edge and motion detection capabilities of human retina in real time would require a generalpurpose computer capable of 10 9 operationssecond 1000 MIPS 80 As of 2011 practical computer vision applications require 10000 to 1000000 MIPS By comparison the fastest supercomputer in 1976 Cray1 retailing at 5 million to 8 million was only capable of around 80 to 130 MIPS and a typical desktop computer at the time achieved less than 1 MIPS Intractability and the combinatorial explosion In 1972 Richard Karp building on Stephen Cook s 1971 theorem showed there are many problems that can probably only be solved in exponential time in the size of the inputs Finding optimal solutions to these problems requires unimaginable amounts of computer time except when the problems are trivial This almost certainly meant that many of the toy solutions used by AI would probably never scale up into useful systems 81 Commonsense knowledge and reasoning Many important artificial intelligence applications like vision or natural language require simply enormous amounts of information about the world the program needs to have some idea of what it might be looking at or what it is talking about This requires that the program know most of the same things about the world that a child does Researchers soon discovered that this was a truly vast amount of information No one in 1970 could build a database so large and no one knew how a program might learn so much information 82 Moravecs paradox Proving theorems and solving geometry problems is comparatively easy for computers but a supposedly simple task like recognizing a face or crossing a room without bumping into anything is extremely difficult This helps explain why research into vision and robotics had made so little progress by the middle 1970s 83 The frame and qualification problems AI researchers like John McCarthy who used logic discovered that they could not represent ordinary deductions that involved planning or default reasoning without making changes to the structure of logic itself They developed new logics like nonmonotonic logics and modal logics to try to solve the problems 84 The end of funding edit See also AI Winter The agencies which funded AI research such as the British government DARPA and NRC became frustrated with the lack of progress and eventually cut off almost all funding for undirected research into AI The pattern began as early as 1966 when the ALPAC report appeared criticizing machine translation efforts After spending 20 million dollars the NRC ended all support 85 In 1973 the Lighthill report on the state of AI research in England criticized the utter failure of AI to achieve its grandiose objectives and led to the dismantling of AI research in that country 86 The report specifically mentioned the combinatorial explosion problem as a reason for AIs failings 87 DARPA was deeply disappointed with researchers working on the Speech Understanding Research program at CMU and canceled an annual grant of three million dollars 88 By 1974 funding for AI projects was hard to find Hans Moravec blamed the crisis on the unrealistic predictions of his colleagues Many researchers were caught up in a web of increasing exaggeration 89 However there was another issue since the passage of the Mansfield Amendment in 1969 DARPA had been under increasing pressure to fund missionoriented direct research rather than basic undirected research Funding for the creative freewheeling exploration that had gone on in the 60s would not come from DARPA Instead the money was directed at specific projects with clear objectives such as autonomous tanks and battle management systems 90 Critiques from across campus edit See also Philosophy of artificial intelligence Several philosophers had strong objections to the claims being made by AI researchers One of the earliest was John Lucas who argued that Gödels incompleteness theorem showed that a formal system such as a computer program could never see the truth of certain statements while a human being could 91 Hubert Dreyfus ridiculed the broken promises of the 1960s and critiqued the assumptions of AI arguing that human reasoning actually involved very little symbol processing and a great deal of embodied instinctive unconscious know how 92 93 John Searle s Chinese Room argument presented in 1980 attempted to show that a program could not be said to understand the symbols that it uses a quality called intentionality If the symbols have no meaning for the machine Searle argued then the machine can not be described as thinking 94 These critiques were not taken seriously by AI researchers often because they seemed so far off the point Problems like intractability and commonsense knowledge seemed much more immediate and serious It was unclear what difference know how or intentionality made to an actual computer program Minsky said of Dreyfus and Searle they misunderstand and should be ignored 95 Dreyfus who taught at MIT was given a cold shoulder he later said that AI researchers dared not be seen having lunch with me 96 Joseph Weizenbaum the author of ELIZA felt his colleagues treatment of Dreyfus was unprofessional and childish Although he was an outspoken critic of Dreyfus positions he deliberately made it plain that theirs was not the way to treat a human being 97 Weizenbaum began to have serious ethical doubts about AI when Kenneth Colby wrote a computer program which can conduct psychotherapeutic dialogue based on ELIZA 98 Weizenbaum was disturbed that Colby saw a mindless program as a serious therapeutic tool A feud began and the situation was not helped when Colby did not credit Weizenbaum for his contribution to the program In 1976 Weizenbaum published Computer Power and Human Reason which argued that the misuse of artificial intelligence has the potential to devalue human life 99 Perceptrons and the attack on connectionism edit A perceptron was a form of neural network introduced in 1958 by Frank Rosenblatt who had been a schoolmate of Marvin Minsky at the Bronx High School of Science Like most AI researchers he was optimistic about their power predicting that perceptron may eventually be able to learn make decisions and translate languages An active research program into the paradigm was carried out throughout the 1960s but came to a sudden halt with the publication of Minsky and Paperts 1969 book Perceptrons It suggested that there were severe limitations to what perceptrons could do and that Frank Rosenblatt s predictions had been grossly exaggerated The effect of the book was devastating virtually no research at all was done in connectionism for 10 years Eventually a new generation of researchers would revive the field and thereafter it would become a vital and useful part of artificial intelligence Rosenblatt would not live to see this as he died in a boating accident shortly after the book was published 74 Utilizing logic and symbolic reasoning edit Logic was introduced into AI research as early as 1958 by John McCarthy in his Advice Taker proposal 100 In 1963 J Alan Robinson had discovered a simple method to implement deduction on computers the resolution and unification algorithm However straightforward implementations like those attempted by McCarthy and his students in the late 1960s were especially intractable the programs required astronomical numbers of steps to prove simple theorems 101 A more fruitful approach to logic was developed in the 1970s by Robert Kowalski at the University of Edinburgh and soon this led to the collaboration with French researchers Alain Colmerauer and Philippe Roussel who created the successful logic programming language Prolog 102 Prolog uses a subset of logic Horn clauses closely related to rules and production rules that permit tractable computation Rules would continue to be influential providing a foundation for Edward Feigenbaum s expert systems and the continuing work by Allen Newell and Herbert A Simon that would lead to Soar and their unified theories of cognition 103 Critics of the logical approach noted as Dreyfus had that human beings rarely used logic when they solved problems Experiments by psychologists like Peter Wason Eleanor Rosch Amos Tversky Daniel Kahneman and others provided proof 104 McCarthy responded that what people do is irrelevant He argued that what is really needed are machines that can solve problemsnot machines that think as people do 105 Another approach frames and scripts edit Among the critics of McCarthys approach were his colleagues across the country at MIT Marvin Minsky Seymour Papert and Roger Schank were trying to solve problems like story understanding and object recognition that required a machine to think like a person In order to use ordinary concepts like chair or restaurant they had to make all the same illogical assumptions that people normally made Unfortunately imprecise concepts like these are hard to represent in logic Gerald Sussman observed that using precise language to describe essentially imprecise concepts doesnt make them any more precise 106 Schank described their antilogic approaches as scruffy as opposed to the neat paradigms used by McCarthy Kowalski Feigenbaum Newell and Simon 107 In 1975 in a seminal paper Minsky noted that many of his fellow scruffy researchers were using the same kind of tool a framework that captures all our common sense assumptions about something For example if we use the concept of a bird there is a constellation of facts that immediately come to mind we might assume that it flies eats worms and so on We know these facts are not always true and that deductions using these facts will not be logical but these structured sets of assumptions are part of the context of everything we say and think He called these structures frames Schank used a version of frames he called scripts to successfully answer questions about short stories in English 108 Many years later objectoriented programming would adopt the essential idea of inheritance from AI research on frames Boom 19801987 edit In the 1980s a form of AI program called expert systems was adopted by corporations around the world and knowledge became the focus of mainstream AI research In those same years the Japanese government aggressively funded AI with its fifth generation computer project Another encouraging event in the early 1980s was the revival of connectionism in the work of John Hopfield and David Rumelhart Once again AI had achieved success 109 The rise of expert systems edit An expert system is a program that answers questions or solves problems about a specific domain of knowledge using logical rules that are derived from the knowledge of experts The earliest examples were developed by Edward Feigenbaum and his students Dendral begun in 1965 identified compounds from spectrometer readings MYCIN developed in 1972 diagnosed infectious blood diseases They demonstrated the feasibility of the approach 110 Expert systems restricted themselves to a small domain of specific knowledge thus avoiding the commonsense knowledge problem and their simple design made it relatively easy for programs to be built and then modified once they were in place All in all the programs proved to be useful something that AI had not been able to achieve up to this point 111 In 1980 an expert system called XCON was completed at CMU for the Digital Equipment Corporation It was an enormous success it was saving the company 40 million dollars annually by 1986 112 Corporations around the world began to develop and deploy expert systems and by 1985 they were spending over a billion dollars on AI most of it to inhouse AI departments An industry grew up to support them including hardware companies like Symbolics and Lisp Machines and software companies such as IntelliCorp and Aion 113 The knowledge revolution edit The power of expert systems came from the expert knowledge they contained They were part of a new direction in AI research that had been gaining ground throughout the 70s AI researchers were beginning to suspectreluctantly for it violated the scientific canon of parsimonythat intelligence might very well be based on the ability to use large amounts of diverse knowledge in different ways 114 writes Pamela McCorduck The great lesson from the 1970s was that intelligent behavior depended very much on dealing with knowledge sometimes quite detailed knowledge of a domain where a given task lay 115 Knowledge based systems and knowledge engineering became a major focus of AI research in the 1980s 116 The 1980s also saw the birth of Cyc the first attempt to attack the commonsense knowledge problem directly by creating a massive database that would contain all the mundane facts that the average person knows Douglas Lenat who started and led the project argued that there is no shortcut the only way for machines to know the meaning of human concepts is to teach them one concept at a time by hand The project was not expected to be completed for many decades 117 Chess playing programs HiTech and Deep Thought defeated chess masters in 1989 Both were developed by Carnegie Mellon University Deep Thought development paved the way for Deep Blue 118 The money returns the Fifth Generation project edit In 1981 the Japanese Ministry of International Trade and Industry set aside 850 million for the Fifth generation computer project Their objectives were to write programs and build machines that could carry on conversations translate languages interpret pictures and reason like human beings 119 Much to the chagrin of scruffies they chose Prolog as the primary computer language for the project 120 Other countries responded with new programs of their own The UK began the 350 million Alvey project A consortium of American companies formed the Microelectronics and Computer Technology Corporation or MCC to fund large scale projects in AI and information technology 121 122 DARPA responded as well founding the Strategic Computing Initiative and tripling its investment in AI between 1984 and 1988 123 A Hopfield net with four nodes The revival of connectionism edit In 1982 physicist John Hopfield was able to prove that a form of neural network now called a Hopfield net could learn and process information in a completely new way Around the same time Geoffrey Hinton and David Rumelhart popularized a method for training neural networks called backpropagation also known as the reverse mode of automatic differentiation published by Seppo Linnainmaa 1970 and applied to neural networks by Paul Werbos These two discoveries helped to revive the field of connectionism 122 124 The new field was unified and inspired by the appearance of Parallel Distributed Processing in 1986a two volume collection of papers edited by Rumelhart and psychologist James McClelland Neural networks would become commercially successful in the 1990s when they began to be used as the engines driving programs like optical character recognition and speech recognition 122 125 Bust the second AI winter 19871993 edit The business communitys fascination with AI rose and fell in the 1980s in the classic pattern of an economic bubble The collapse was in the perception of AI by government agencies and investors the field continued to make advances despite the criticism Rodney Brooks and Hans Moravec researchers from the related field of robotics argued for an entirely new approach to artificial intelligence A New and Different AI winter edit The term AI winter was coined by researchers who had survived the funding cuts of 1974 when they became concerned that enthusiasm for expert systems had spiraled out of control and that disappointment would certainly follow 126 Their fears were well founded in the late 1980s and early 1990s AI suffered a series of financial setbacks The first indication of a change in weather was the sudden collapse of the market for specialized AI hardware in 1987 Desktop computers from Apple and IBM had been steadily gaining speed and power and in 1987 they became more powerful than the more expensive Lisp machines made by Symbolics and others There was no longer a good reason to buy them An entire industry worth half a billion dollars was demolished overnight 127 Eventually the earliest successful expert systems such as XCON proved too expensive to maintain They were difficult to update they could not learn they were brittle ie they could make grotesque mistakes when given unusual inputs and they fell prey to problems such as the qualification problem that had been identified years earlier Expert systems proved useful but only in a few special contexts 128 In the late 1980s the Strategic Computing Initiative cut funding to AI deeply and brutally New leadership at DARPA had decided that AI was not the next wave and directed funds towards projects that seemed more likely to produce immediate results 129 By 1991 the impressive list of goals penned in 1981 for Japans Fifth Generation Project had not been met Indeed some of them like carry on a casual conversation had not been met by 2010 130 As with other AI projects expectations had run much higher than what was actually possible 130 Over 300 AI companies had shutdown gone bankrupt or been acquired by the end of 1993 effectively ending the first commercial wave of AI 131 The importance of having a body nouvelle AI and embodied reason edit Main articles Nouvelle AI behaviorbased AI situated and embodied cognitive science In the late 1980s several researchers advocated a completely new approach to artificial intelligence based on robotics 132 They believed that to show real intelligence a machine needs to have a body it needs to perceive move survive and deal with the world They argued that these sensorimotor skills are essential to higher level skills like commonsense reasoning and that abstract reasoning was actually the least interesting or important human skill see Moravecs paradox They advocated building intelligence from the bottom up 133 The approach revived ideas from cybernetics and control theory that had been unpopular since the sixties Another precursor was David Marr who had come to MIT in the late 1970s from a successful background in theoretical neuroscience to lead the group studying vision He rejected all symbolic approaches both McCarthys logic and Minsky s frames arguing that AI needed to understand the physical machinery of vision from the bottom up before any symbolic processing took place Marrs work would be cut short by leukemia in 1980 134 In a 1990 paper Elephants Dont Play Chess 135 robotics researcher Rodney Brooks took direct aim at the physical symbol system hypothesis arguing that symbols are not always necessary since the world is its own best model It is always exactly up to date It always has every detail there is to be known The trick is to sense it appropriately and often enough 136 In the 1980s and 1990s many cognitive scientists also rejected the symbol processing model of the mind and argued that the body was essential for reasoning a theory called the embodied mind thesis 137 AI 19932011 edit The field of AI now more than a half a century old finally achieved some of its oldest goals It began to be used successfully throughout the technology industry although somewhat behind the scenes Some of the success was due to increasing computer power and some was achieved by focusing on specific isolated problems and pursuing them with the highest standards of scientific accountability Still the reputation of AI in the business world at least was less than pristine Inside the field there was little agreement on the reasons for AIs failure to fulfill the dream of human level intelligence that had captured the imagination of the world in the 1960s Together all these factors helped to fragment AI into competing subfields focused on particular problems or approaches sometimes even under new names that disguised the tarnished pedigree of artificial intelligence 138 AI was both more cautious and more successful than it had ever been Milestones and Moores law edit On 11 May 1997 Deep Blue became the first computer chessplaying system to beat a reigning world chess champion Garry Kasparov 139 The super computer was a specialized version of a framework produced by IBM and was capable of processing twice as many moves per second as it had during the first match which Deep Blue had lost reportedly 200000000 moves per second The event was broadcast live over the internet and received over 74 million hits 140 In 2005 a Stanford robot won the DARPA Grand Challenge by driving autonomously for 131 miles along an unrehearsed desert trail 141 Two years later a team from CMU won the DARPA Urban Challenge by autonomously navigating 55 miles in an Urban environment while adhering to traffic hazards and all traffic laws 142 In February 2011 in a Jeopardy quiz show exhibition match IBM s question answering system Watson defeated the two greatest Jeopardy champions Brad Rutter and Ken Jennings by a significant margin 143 These successes were not due to some revolutionary new paradigm but mostly on the tedious application of engineering skill and on the tremendous increase in the speed and capacity of computer by the 90s 144 In fact Deep Blues computer was 10 million times faster than the Ferranti Mark 1 that Christopher Strachey taught to play chess in 1951 145 This dramatic increase is measured by Moores law which predicts that the speed and memory capacity of computers doubles every two years The fundamental problem of raw computer power was slowly being overcome Intelligent agents edit A new paradigm called intelligent agents became widely accepted during the 1990s 146 Although earlier researchers had proposed modular divide and conquer approaches to AI 147 the intelligent agent did not reach its modern form until Judea Pearl Allen Newell Leslie P Kaelbling and others brought concepts from decision theory and economics into the study of AI 148 When the economists definition of a rational agent was married to computer science s definition of an object or module the intelligent agent paradigm was complete An intelligent agent is a system that perceives its environment and takes actions which maximize its chances of success By this definition simple programs that solve specific problems are intelligent agents as are human beings and organizations of human beings such as firms The intelligent agent paradigm defines AI research as the study of intelligent agents This is a generalization of some earlier definitions of AI it goes beyond studying human intelligence it studies all kinds of intelligence 149 The paradigm gave researchers license to study isolated problems and find solutions that were both verifiable and useful It provided a common language to describe problems and share their solutions with each other and with other fields that also used concepts of abstract agents like economics and control theory It was hoped that a complete agent architecture like Newells SOAR would one day allow researchers to build more versatile and intelligent systems out of interacting intelligent agents 148 150 Implementation of Rigor edit AI researchers began to develop and use sophisticated mathematical tools more than they ever had in the past 151 There was a widespread realization that many of the problems that AI needed to solve were already being worked on by researchers in fields like mathematics economics or operations research The shared mathematical language allowed both a higher level of collaboration with more established and successful fields and the achievement of results which were measurable and provable AI had become a more rigorous scientific discipline Russell Norvig 2003 describe this as nothing less than a revolution and the victory of the neats 152 153 Judea Pearl s influential 1988 book 154 brought probability and decision theory into AI Among the many new tools in use were Bayesian networks hidden Markov models information theory stochastic modeling and classical optimization Precise mathematical descriptions were also developed for computational intelligence paradigms like neural networks and evolutionary algorithms 152 AI behind the scenes edit Algorithms originally developed by AI researchers began to appear as parts of larger systems AI had solved a lot of very difficult problems 155 and their solutions proved to be useful throughout the technology industry 156 such as data mining industrial robotics logistics 157 speech recognition 158 banking software 159 medical diagnosis 159 and Google s search engine 160 The field of AI received little or no credit for these successes in the 1990s and early 2000s Many of AIs greatest innovations have been reduced to the status of just another item in the tool chest of computer science 161 Nick Bostrom explains A lot of cutting edge AI has filtered into general applications often without being called AI because once something becomes useful enough and common enough its not labeled AI anymore 162 Many researchers in AI in 1990s deliberately called their work by other names such as informatics knowledgebased systems cognitive systems or computational intelligence In part this may be because they considered their field to be fundamentally different from AI but also the new names help to procure funding In the commercial world at least the failed promises of the AI Winter continued to haunt AI research into the 2000s as the New York Times reported in 2005 Computer scientists and software engineers avoided the term artificial intelligence for fear of being viewed as wildeyed dreamers 163 164 165 Predictions edit In 1968 Arthur C Clarke and Stanley Kubrick had imagined that by the year 2001 a machine would exist with an intelligence that matched or exceeded the capability of human beings The character they created HAL 9000 was based on a belief shared by many leading AI researchers that such a machine would exist by the year 2001 166 In 2001 AI founder Marvin Minsky asked So the question is why didnt we get HAL in 2001 167 Minsky believed that the answer is that the central problems like commonsense reasoning were being neglected while most researchers pursued things like commercial applications of neural nets or genetic algorithms John McCarthy on the other hand still blamed the qualification problem 168 For Ray Kurzweil the issue is computer power and using Moores Law he predicted that machines with humanlevel intelligence will appear by 2029 169 Jeff Hawkins argued that neural net research ignores the essential properties of the human cortex preferring simple models that have been successful at solving simple problems 170 There were many other explanations and for each there was a corresponding research program underway Deep learning big data and artificial general intelligence 2011present edit In the first decades of the 21st century access to large amounts of data known as big data cheaper and faster computers and advanced machine learning techniques were successfully applied to many problems throughout the economy In fact McKinsey Global Institute estimated in their famous paper Big data The next frontier for innovation competition and productivity that by 2009 nearly all sectors in the US economy had at least an average of 200 terabytes of stored data By 2016 the market for AIrelated products hardware and software reached more than 8 billion dollars and the New York Times reported that interest in AI had reached a frenzy 171 The applications of big data began to reach into other fields as well such as training models in ecology 172 and for various applications in economics 173 Advances in deep learning particularly deep convolutional neural networks and recurrent neural networks drove progress and research in image and video processing text analysis and even speech recognition 174 Deep learning edit Main article Deep learning Deep learning is a branch of machine learning that models high level abstractions in data by using a deep graph with many processing layers 174 According to the Universal approximation theorem deepness isnt necessary for a neural network to be able to approximate arbitrary continuous functions Even so there are many problems that are common to shallow networks such as overfitting that deep networks help avoid 175 As such deep neural networks are able to realistically generate much more complex models as compared to their shallow counterparts However deep learning has problems of its own A common problem for recurrent neural networks is the vanishing gradient problem which is where gradients passed between layers gradually shrink and literally disappear as they are rounded off to zero There have been many methods developed to approach this problem such as Long shortterm memory units Stateoftheart deep neural network architectures can sometimes even rival human accuracy in fields like computer vision specifically on things like the MNIST database and traffic sign recognition 176 Language processing engines powered by smart search engines can easily beat humans at answering general trivia questions such as IBM Watson and recent developments in deep learning have produced astounding results in competing with humans in things like Go and Doom which being a FirstPerson Shooter game has sparked some controversy 177 178 179 180 Big Data edit Main article Big Data Big data refers to a collection of data that cannot be captured managed and processed by conventional software tools within a certain time frame It is a massive amount of decisionmaking insight and process optimization capabilities that require new processing models In the Big Data Era written by Victor Meyer Schonberg and Kenneth Cooke big data means that instead of random analysis sample survey all data is used for analysis The 5V characteristics of big data proposed by IBM Volume Velocity Variety 181 Value 182 Veracity 183 The strategic significance of big data technology is not to master huge data information but to specialize in these meaningful data In other words if big data is likened to an industry the key to realizing profitability in this industry is to increase the Process capability of the data and realize the Value added of the data through Processing Artificial general intelligence edit Main article Artificial general intelligence Artificial intelligence is a branch of computer science that attempts to understand the essence of intelligence and produce a new intelligent machine that responds in a manner similar to human intelligence Research in this area includes robotics speech recognition image recognition Natural language processing and expert systems Since the birth of artificial intelligence the theory and technology have become more and more mature and the application fields have been expanding It is conceivable that the technological products brought by artificial intelligence in the future will be the container of human wisdom Artificial intelligence can simulate the information process of human consciousness and thinking Artificial intelligence is not human intelligence but it can be like human thinking and it may exceed human intelligenceArtificial general intelligence is also referred to as strong AI 184 full AI 185 or as the ability of a machine to perform general intelligent action Academic sources reserve strong AI to refer to machines capable of experiencing consciousness See also edit Outline of artificial intelligence Progress in artificial intelligence Timeline of artificial intelligence History of natural language processing Timeline of machine learning Notes edit Kaplan Andreas Haenlein Michael 2019 Siri Siri in my hand Whos the fairest in the land On the interpretations illustrations and implications of artificial intelligence Business Horizons 62 1525 doi 101016jbushor201808004 mwparseroutput citecitationfontstyleinheritmwparseroutput citation qquotesmwparseroutput idlockfree amwparseroutput citation cs1lockfree abackgroundurluploadwikimediaorgwikipediacommonsthumb665Lockgreensvg9pxLockgreensvgpngnorepeatbackgroundpositionright 1em centermwparseroutput idlocklimited amwparseroutput idlockregistration amwparseroutput citation cs1locklimited amwparseroutput citation cs1lockregistration abackgroundurluploadwikimediaorgwikipediacommonsthumbdd6Lockgrayalt2svg9pxLockgrayalt2svgpngnorepeatbackgroundpositionright 1em centermwparseroutput idlocksubscription amwparseroutput citation cs1locksubscription abackgroundurluploadwikimediaorgwikipediacommonsthumbaaaLockredalt2svg9pxLockredalt2svgpngnorepeatbackgroundpositionright 1em centermwparseroutput cs1subscriptionmwparseroutput cs1registrationcolor555mwparseroutput cs1subscription spanmwparseroutput cs1registration spanborderbottom1px dottedcursorhelpmwparseroutput cs1wsicon abackgroundurluploadwikimediaorgwikipediacommonsthumb44cWikisourcelogosvg12pxWikisourcelogosvgpngnorepeatbackgroundpositionright 1em centermwparseroutput codecs1codecolorinheritbackgroundinheritborderinheritpaddinginheritmwparseroutput cs1hiddenerrordisplaynonefontsize100mwparseroutput cs1visibleerrorfontsize100mwparseroutput cs1maintdisplaynonecolor33aa33marginleft03emmwparseroutput cs1subscriptionmwparseroutput cs1registrationmwparseroutput cs1formatfontsize95mwparseroutput cs1kernleftmwparseroutput cs1kernwlleftpaddingleft02emmwparseroutput cs1kernrightmwparseroutput cs1kernwlrightpaddingright02em McCorduck 2004 p5 Russell Norvig 2003 p939 McCorduck 2004 pp1516 Buchanan 2005 p50 Judah Loew s Golem McCorduck 2004 pp1314 Paracelsus OConnor 1994 Gebers Takwin McCorduck 2004 pp1725 Butler 1863 Needham 1986 p53 McCorduck 2004 p6 Nick 2005 McCorduck 2004 p17 and see also Levitt 2000 Quoted in McCorduck 2004 p8 Crevier 1993 p1 and McCorduck 2004 pp69 discusses sacred statues Other important automatons were built by Haroun alRashid McCorduck 2004 p10 Jacques de Vaucanson McCorduck 2004 p16 and Leonardo Torres y Quevedo McCorduck 2004 pp5962 a b c d Berlinski 2000 Cfr Carreras Artau Tomás y Joaquín Historia de la filosofía española Filosofía cristiana de los siglos XIII al XV Madrid 1939 Volume I Bonner Anthonny The Art and Logic of Ramón Llull A Users Guide Brill 2007 Anthony Bonner ed Doctor Illuminatus A Ramon Llull Reader Princeton University 1985 Vid Llulls Influence The History of Lullism at 5771 17th century mechanism and AI McCorduck 2004 pp3746 Russell Norvig 2003 p6 Haugeland 1986 chpt 2 Buchanan 2005 p53 Hobbes and AI McCorduck 2004 p42 Hobbes 1651 chapter 5 Leibniz and AI McCorduck 2004 p41 Russell Norvig 2003 p6 Berlinski 2000 p12 Buchanan 2005 p53 The Lambda calculus was especially important to AI since it was an inspiration for Lisp the most important programming language used in AI Crevier 1993 pp19019661 The original photo can be seen in the article Rose Allen April 1946 Lightning Strikes Mathematics Popular Science 8386 Retrieved 15 April 2012 The Turing machine McCorduck 2004 pp6364 Crevier 1993 pp2224 Russell Norvig 2003 p8 and see Turing 1936 Menabrea 1843 McCorduck 2004 pp6162 6466 Russell Norvig 2003 pp1415 McCorduck 2004 pp7680 McCorduck 2004 pp5157 80107 Crevier 1993 pp2732 Russell Norvig 2003 pp15 940 Moravec 1988 p3 Cordeschi 2002 Chap 5 McCorduck 2004 p98 Crevier 1993 pp2728 Russell Norvig 2003 pp15 940 Moravec 1988 p3 Cordeschi 2002 Chap 5 McCorduck 2004 pp5157 8894 Crevier 1993 p30 Russell Norvig 2003 p1516 Cordeschi 2002 Chap 5 and see also Pitts McCullough 1943 McCorduck 2004 p102 Crevier 1993 pp3435 and Russell Norvig 2003 p17 McCorduck 2004 pp7072 Crevier 1993 p2225 Russell Norvig 2003 pp23 and 948 Haugeland 1985 pp69 Cordeschi 2002 pp170176See also Turing 1950 Norvig Russell 2003 p948 claim that Turing answered all the major objections to AI that have been offered in the years since the paper appeared See A Brief History of Computing at AlanTuringnet Schaeffer Jonathan One Jump Ahead Challenging Human Supremacy in Checkers 19972009 Springer ISBN 9780387765754 Chapter 6 McCorduck 2004 pp137170 Crevier pp4447 McCorduck 2004 pp123125 Crevier 1993 pp4446 and Russell Norvig 2003 p17 Quoted in Crevier 1993 p46 and Russell Norvig 2003 p17 Russell Norvig 2003 p947952 McCorduck 2004 pp111136 Crevier 1993 pp4951 and Russell Norvig 2003 p17 Newquist 1994 pp91112 See McCarthy et al 1955 Also see Crevier 1993 p48 where Crevier states the proposal later became known as the physical symbol systems hypothesis The physical symbol system hypothesis was articulated and named by Newell and Simon in their paper on GPS Newell Simon 1963 It includes a more specific definition of a machine as an agent that manipulates symbols See the philosophy of artificial intelligence McCorduck 2004 pp129130 discusses how the Dartmouth conference alumni dominated the first two decades of AI research calling them the invisible college I wont swear and I hadnt seen it before McCarthy told Pamela McCorduck in 1979 McCorduck 2004 p114 However McCarthy also stated unequivocally I came up with the term in a CNET interview Skillings 2006 Crevier 1993 pp49 writes the conference is generally recognized as the official birthdate of the new science McCarthy John 1988 Review of The Question of Artificial Intelligence Annals of the History of Computing 10 3 224229 collected in McCarthy John 1996 10 Review of The Question of Artificial Intelligence Defending AI Research A Collection of Essays and Reviews CSLI p 73One of the reasons for inventing the term artificial intelligence was to escape association with cybernetics Its concentration on analog feedback seemed misguided and I wished to avoid having either to accept Norbert not Robert Wiener as a guru or having to argue with him Russell and Norvig write it was astonishing whenever a computer did anything remotely clever Russell Norvig 2003 p18 Crevier 1993 pp52107 Moravec 1988 p9 and Russell Norvig 2003 p1821 McCorduck 2004 p218 Newquist 1994 pp91112 Crevier 1993 pp108109 and Russell Norvig 2003 p21 Crevier 1993 pp52107 Moravec 1988 p9 Meansends analysis reasoning as search McCorduck 2004 pp247248 Russell Norvig 2003 pp5961 Heuristic McCorduck 2004 p246 Russell Norvig 2003 pp2122 GPS McCorduck 2004 pp245250 Crevier 1993 pGPS Russell Norvig 2003 pGPS Crevier 1993 pp51586566 and Russell Norvig 2003 pp1819 McCorduck 2004 pp268271 Crevier 1993 pp9596 Newquist 1994 pp148156 Moravec 1988 pp1415 McCorduck 2004 p286 Crevier 1993 pp7679 Russell Norvig 2003 p19 Crevier 1993 pp7983 Crevier 1993 pp164172 McCorduck 2004 pp291296 Crevier 1993 pp134139 McCorduck 2004 pp299305 Crevier 1993 pp83102 Russell Norvig 2003 p19 and Copeland 2000 McCorduck 2004 pp300305 Crevier 1993 pp84102 Russell Norvig 2003 p19 Simon Newell 1958 p78 quoted in Crevier 1993 p108 See also Russell Norvig 2003 p21 Simon 1965 p96 quoted in Crevier 1993 p109 Minsky 1967 p2 quoted in Crevier 1993 p109 Minsky strongly believes he was misquoted See McCorduck 2004 pp272274 Crevier 1993 p96 and Darrach 1970 Crevier 1993 pp6465 Crevier 1993 p94 Howe 1994 McCorduck 2004 p131 Crevier 1993 p51 McCorduck also notes that funding was mostly under the direction of alumni of the Dartmouth conference of 1956 Crevier 1993 p65 Crevier 1993 pp6871 and Turkle 1984 Humanoid History WABOT Robotics and Mechatronics Proceedings of the 4th IFToMM International Symposium on Robotics and Mechatronics page 66 Historical Android Projects androidworldcom Robots From Science Fiction to Technological Revolution page 130 Handbook of Digital Human Modeling Research for Applied Ergonomics and Human Factors Engineering Chapter 3 pages 12 Crevier 1993 pp100144 and Russell Norvig 2003 pp2122 a b McCorduck 2004 pp104107 Crevier 1993 pp102105 Russell Norvig 2003 p22 Crevier 1993 pp163196 Crevier 1993 p146 Russell Norvig 2003 pp2021 Crevier 1993 pp146148 see also Buchanan 2005 p56 Early programs were necessarily limited in scope by the size and speed of memory Moravec 1976 McCarthy has always disagreed with Moravec back to their early days together at SAIL He states I would say that 50 years ago the machine capability was much too small but by 30 years ago machine capability wasnt the real problem in a CNET interview Skillings 2006 Hans Moravec ROBOT Mere Machine to Transcendent Mind Russell Norvig 2003 pp92122 and Lighthill 1973 McCorduck 2004 pp300 421 Crevier 1993 pp113114 Moravec 1988 p13 Lenat Guha 1989 Introduction Russell Norvig 2003 p21 McCorduck 2004 p456 Moravec 1988 pp1516 McCarthy Hayes 1969 Crevier 1993 pp117119 McCorduck 2004 pp280281 Crevier 1993 p110 Russell Norvig 2003 p21 and NRC 1999 under Success in Speech Recognition Crevier 1993 p117 Russell Norvig 2003 p22 Howe 1994 and see also Lighthill 1973 Russell Norvig 2003 p22 Lighthill 1973 John McCarthy wrote in response that the combinatorial explosion problem has been recognized in AI from the beginning in Review of Lighthill report Crevier 1993 pp115116 on whom this account is based Other views include McCorduck 2004 pp306313 and NRC 1999 under Success in Speech Recognition Crevier 1993 p115 Moravec explains Their initial promises to DARPA had been much too optimistic Of course what they delivered stopped considerably short of that But they felt they couldnt in their next proposal promise less than in the first one so they promised more NRC 1999 under Shift to Applied Research Increases Investment While the autonomous tank was a failure the battle management system called DART proved to be enormously successful saving billions in the first Gulf War repaying the investment and justifying the DARPA s pragmatic policy at least as far as DARPA was concerned Lucas and Penrose critique of AI Crevier 1993 p22 Russell Norvig 2003 pp949950 Hofstadter 1980 pp471477 and see Lucas 1961 Knowhow is Dreyfus term Dreyfus makes a distinction between knowing how and knowing that a modern version of Heidegger s distinction of readytohand and presentathand Dreyfus Dreyfus 1986 Dreyfus critique of artificial intelligence McCorduck 2004 pp211239 Crevier 1993 pp120132 Russell Norvig 2003 pp950952 and see Dreyfus 1965 Dreyfus 1972 Dreyfus Dreyfus 1986 Searles critique of AI McCorduck 2004 pp443445 Crevier 1993 pp269271 Russell Norvig 2004 pp958960 and see Searle 1980 Quoted in Crevier 1993 p143 Quoted in Crevier 1993 p122 I became the only member of the AI community to be seen eating lunch with Dreyfus And I deliberately made it plain that theirs was not the way to treat a human being Joseph Weizenbaum quoted in Crevier 1993 p123 Colby Watt Gilbert 1966 p148 Weizenbaum referred to this text in Weizenbaum 1976 pp5 6 Colby and his colleagues later also developed chatterbot like computer simulations of paranoid processes PARRY to make intelligble paranoid processes in explicit symbol processing terms Colby 1974 p6 Weizenbaums critique of AI McCorduck 2004 pp356373 Crevier 1993 pp132144 Russell Norvig 2003 p961 and see Weizenbaum 1976 McCorduck 2004 p51 Russell Norvig 2003 pp19 23 McCorduck 2004 p51 Crevier 1993 pp190192 Crevier 1993 pp193196 Crevier 1993 pp14514925863 Wason 1966 showed that people do poorly on completely abstract problems but if the problem is restated to allow the use of intuitive social intelligence performance dramatically improves See Wason selection task Tversky Slovic Kahnemann 1982 have shown that people are terrible at elementary problems that involve uncertain reasoning See list of cognitive biases for several examples Eleanor Rosch s work is described in Lakoff 1987 An early example of McCathys position was in the journal Science where he said This is AI so we dont care if its psychologically real Kolata 2012 and he recently reiterated his position at the AI50 conference where he said Artificial intelligence is not by definition simulation of human intelligence Maker 2006 Crevier 1993 pp175 Neat vs scruffy McCorduck 2004 pp421424 who picks up the state of the debate in 1984 Crevier 1993 pp168 who documents Schanks original use of the term Another aspect of the conflict was called the proceduraldeclarative distinction but did not prove to be influential in later AI research McCorduck 2004 pp305306 Crevier 1993 pp170173 246 and Russell Norvig 2003 p24 Minskys frame paper Minsky 1974 Newquist 1994 pp189192 McCorduck 2004 pp327335 Dendral Crevier 1993 pp148159 Newquist 1994 p271 Russell Norvig 2003 pp2223 Crevier 1993 pp158159 and Russell Norvig 2003 p2324 Crevier 1993 p198 McCorduck 2004 pp434435 Crevier 1993 pp161162197203 and Russell Norvig 2003 p24 McCorduck 2004 p299 McCorduck 2004 pp421 Knowledge revolution McCorduck 2004 pp266276 298300 314 421 Newquist 1994 pp255267 Russell Norvig pp2223 Cyc McCorduck 2004 p489 Crevier 1993 pp239243 Newquist 1994 pp431455 Russell Norvig 2003 p363365 and Lenat Guha 1989 Chess Checkmate PDF Retrieved 1 September 2007 McCorduck 2004 pp436441 Newquist 1994 pp231240 Crevier 1993 pp211 Russell Norvig 2003 p24 and see also Feigenbaum McCorduck 1983 Crevier 1993 pp195 Crevier 1993 pp240 a b c Russell Norvig 2003 p25 McCorduck 2004 pp426432 NRC 1999 under Shift to Applied Research Increases Investment Crevier 1993 pp214215 Crevier 1993 pp215216 Crevier 1993 pp203 AI winter was first used as the title of a seminar on the subject for the Association for the Advancement of Artificial Intelligence Newquist 1994 pp359379 McCorduck 2004 p435 Crevier 1993 pp209210 McCorduck 2004 p435 who cites institutional reasons for their ultimate failure Newquist 1994 pp258283 who cites limited deployment within corporations Crevier 1993 pp204208 who cites the difficulty of truth maintenance ie learning and updating Lenat Guha 1989 Introduction who emphasizes the brittleness and the inability to handle excessive qualification McCorduck 2004 pp430431 a b McCorduck 2004 p441 Crevier 1993 p212 McCorduck writes Two and a half decades later we can see that the Japanese didnt quite meet all of those ambitious goals Newquist HP 1994 The Brain Makers Genius Ego And Greed In The Quest For Machines That Think New York MacmillanSAMS ISBN 9780672304125 McCorduck 2004 pp454462 Moravec 1988 p20 writes I am confident that this bottomup route to artificial intelligence will one date meet the traditional topdown route more than half way ready to provide the real world competence and the commonsense knowledge that has been so frustratingly elusive in reasoning programs Fully intelligent machines will result when the metaphorical golden spike is driven uniting the two efforts Crevier 1993 pp183190 httppeoplecsailmitedubrookspaperselephantspdf Brooks 1990 p3 See for example Lakoff Turner 1999 McCorduck 2004 p424 discusses the fragmentation and the abandonment of AIs original goals McCorduck 2004 pp480483 Deep Blue IBM Research Retrieved 10 September 2010 DARPA Grand Challenge home page Archived 31 October 2007 at the Wayback Machine httparchivedarpamilgrandchallenge Markoff John 16 February 2011 On Jeopardy Watson Win Is All but Trivial The New York Times Kurzweil 2005 p274 writes that the improvement in computer chess according to common wisdom is governed only by the brute force expansion of computer hardware Cycle time of Ferranti Mark 1 was 12milliseconds which is arguably equivalent to about 833 flops Deep Blue ran at 1138 gigaflops and this does not even take into account Deep Blues specialpurpose hardware for chess Very approximately these differ by a factor of 107 McCorduck 2004 pp471478 Russell Norvig 2003 p55 where they write The wholeagent view is now widely accepted in the field The intelligent agent paradigm is discussed in major AI textbooks such as Russell Norvig 2003 pp3258 968972 Poole Mackworth Goebel 1998 pp721 Luger Stubblefield 2004 pp235240 Carl Hewitt s Actor model anticipated the modern definition of intelligent agents Hewitt Bishop Steiger 1973 Both John Doyle Doyle 1983 and Marvin Minsky s popular classic The Society of Mind Minsky 1986 used the word agent Other modular proposals included Rodney Brooks subsumption architecture objectoriented programming and others a b Russell Norvig 2003 pp27 55 This is how the most widely accepted textbooks of the 21st century define artificial intelligence See Russell Norvig 2003 p32 and Poole Mackworth Goebel 1998 p1 McCorduck 2004 p478 McCorduck 2004 pp486487 Russell Norvig 2003 pp2526 a b Russell Norvig 2003 p2526 McCorduck 2004 p487 As I write AI enjoys a Neat hegemony Pearl 1988 See Applications of artificial intelligence Computer science NRC 1999 under Artificial Intelligence in the 90s and Kurzweil 2005 p264 Russell Norvig 2003 p28 For the new state of the art in AI based speech recognition see The Economist 2007 a b AIinspired systems were already integral to many everyday technologies such as internet search engines bank software for processing transactions and in medical diagnosis Nick Bostrom quoted in CNN 2006 Olsen 2004 Olsen 2006 McCorduck 2004 p423 Kurzweil 2005 p265 Hofstadter 1979 p601 CNN 2006 Markoff 2005 The Economist 2007 Tascarella 2006 Crevier 1993 pp108109 He goes on to say The answer is I believe we could have I once went to an international conference on neural nets There were 40 thousand registrants but if you had an international conference for example on using multiple representations for common sense reasoning Ive only been able to find 6 or 7 people in the whole world Minsky 2001 Maker 2006 Kurzweil 2005 Hawkins Blakeslee 2004 Steve Lohr 17 October 2016 IBM Is Counting on Its Bet on Watson and Paying Big Money for It New York Times Hampton Stephanie E Strasser Carly A Tewksbury Joshua J Gram Wendy K Budden Amber E Batcheller Archer L Duke Clifford S Porter John H 1 April 2013 Big data and the future of ecology Frontiers in Ecology and the Environment 11 3 156162 doi 101890120103 ISSN 15409309 How Big Data is Changing Economies Becker Friedman Institute bfiuchicagoedu Retrieved 9 June 2017 a b LeCun Yann Bengio Yoshua Hinton Geoffrey 2015 Deep learning Nature 521 7553 436444 Bibcode 2015Natur521436L doi 101038nature14539 PMID 26017442 Baral Chitta Fuentes Olac Kreinovich Vladik June 2015 Why Deep Neural Networks A Possible Theoretical Explanation Departmental Technical Reports Cs Retrieved 9 June 2017 Ciregan D Meier U Schmidhuber J June 2012 Multicolumn deep neural networks for image classification 2012 IEEE Conference on Computer Vision and Pattern Recognition pp36423649 arXiv 12022745 Bibcode 2012arXiv12022745C CiteSeerX 10113003283 doi 101109cvpr20126248110 ISBN 9781467312288 Markoff John 16 February 2011 On Jeopardy Watson Win Is All but Trivial The New York Times ISSN 03624331 Retrieved 10 June 2017 AlphaGo Mastering the ancient game of Go with Machine Learning Research Blog Retrieved 10 June 2017 Innovations of AlphaGo DeepMind DeepMind Retrieved 10 June 2017 University Carnegie Mellon Computer OutPlays Humans in DoomCMU News Carnegie Mellon University wwwcmuedu Retrieved 10 June 2017 Laney Doug 2001 3D data management Controlling data volume velocity and variety META Group Research Note 6 70 Marr Bernard 6 March 2014 Big Data The 5 Vs Everyone Must Know Goes Paulo B 2014 Design science research in top information systems journals MIS Quarterly Management Information Systems 38 1 Kurzweil 2005 p260 or see Advanced Human Intelligence where he defines strong AI as machine intelligence with the full range of human intelligence The Age of Artificial Intelligence George John at TEDxLondonBusinessSchool 2013 References edit mwparseroutput refbeginfontsize90marginbottom05emmwparseroutput refbeginhangingindentsgtulliststyletypenonemarginleft0mwparseroutput refbeginhangingindentsgtulgtlimwparseroutput refbeginhangingindentsgtdlgtddmarginleft0paddingleft32emtextindent32emliststylenonemwparseroutput refbegin100fontsize100 Berlinski David 2000 The Advent of the Algorithm Harcourt Books ISBN 9780156013918 OCLC 46890682 Buchanan Bruce G Winter 2005 A Very Brief History of Artificial Intelligence PDF AI Magazine pp5360 archived from the original PDF on 26 December 2007 retrieved 30 August 2007 Brooks Rodney 1990 Elephants Dont Play Chess PDF Robotics and Autonomous Systems 6 12 315 CiteSeerX 10115887539 doi 101016S0921889005800259 retrieved 30 August 2007 Butler Samuel 13 June 1863 Darwin Among the Machines The Press Christchurch New Zealand retrieved 10 October 2008 Colby Kenneth M Watt James B Gilbert John P 1966 A Computer Method of Psychotherapy Preliminary Communication The Journal of Nervous and Mental Disease vol142 no2 pp148152 doi 1010970000505319660200000005 retrieved 17 June 2018 Colby Kenneth M September 1974 Ten Criticisms of Parry PDF Stanford Artificial Intelligence Laboratory REPORT NO STANCS74457 retrieved 17 June 2018 CNN 26 July 2006 AI set to exceed human brain power CNNcom retrieved 16 October 2007 Copeland Jack 2000 MicroWorld AI retrieved 8 October 2008 Cordeschi Roberto 2002 The Discovery of the Artificial Dordrecht Kluwer Crevier Daniel 1993 AI The Tumultuous Search for Artificial Intelligence New York NY BasicBooks ISBN 0465029973 Darrach Brad 20 November 1970 Meet Shaky the First Electronic Person Life Magazine pp5868 Doyle J 1983 What is rational psychology Toward a modern mental philosophy AI Magazine vol4 no3 pp5053 Dreyfus Hubert 1965 Alchemy and AI RAND Corporation Memo Dreyfus Hubert 1972 What Computers Cant Do New York MIT Press ISBN 9780060906139 OCLC 5056816 The Economist 7 June 2007 Are You Talking to Me The Economist retrieved 16 October 2008 Feigenbaum Edward A McCorduck Pamela 1983 The Fifth Generation Artificial Intelligence and Japans Computer Challenge to the World Michael Joseph ISBN 9780718124014 Hawkins Jeff Blakeslee Sandra 2004 On Intelligence New York NY Owl Books ISBN 9780805078534 OCLC 61273290 Hebb DO 1949 The Organization of Behavior New York Wiley ISBN 9780805843002 OCLC 48871099 Hewitt Carl Bishop Peter Steiger Richard 1973 A Universal Modular Actor Formalism for Artificial Intelligence PDF IJCAI archived from the original PDF on 29 December 2009 Hobbes Thomas 1651 Leviathan Hofstadter Douglas 1999 1979 Gödel Escher Bach an Eternal Golden Braid Basic Books ISBN 9780465026562 OCLC 225590743 Howe J November 1994 Artificial Intelligence at Edinburgh University a Perspective retrieved 30 August 2007 Kaplan Andreas Haenlein Michael 2018 Siri Siri in my Hand whos the Fairest in the Land On the Interpretations Illustrations and Implications of Artificial Intelligence Business Horizons 62 1525 doi 101016jbushor201808004 Kolata G 1982 How can computers get common sense Science 217 4566 12371238 Bibcode 1982Sci2171237K doi 101126science21745661237 PMID 17837639 Kurzweil Ray 2005 The Singularity is Near Viking Press ISBN 9780143037880 OCLC 71826177 Lakoff George 1987 Women Fire and Dangerous Things What Categories Reveal About the Mind University of Chicago Press ISBN 9780226468044 Lenat Douglas Guha R V 1989 Building Large KnowledgeBased Systems AddisonWesley ISBN 9780201517521 OCLC 19981533 Levitt Gerald M 2000 The Turk Chess Automaton Jefferson NC McFarland ISBN 9780786407781 Lighthill Professor Sir James 1973 Artificial Intelligence A General Survey Artificial Intelligence a paper symposium Science Research Council Lucas John 1961 Minds Machines and Gödel Philosophy 36 XXXVI 112127 doi 101017S0031819100057983 retrieved 15 October 2008 Maker Meg Houston 2006 AI50 AI Past Present Future Dartmouth College archived from the original on 8 October 2008 retrieved 16 October 2008 Markoff John 14 October 2005 Behind Artificial Intelligence a Squadron of Bright Real People The New York Times retrieved 16 October 2008 McCarthy John Minsky Marvin Rochester Nathan Shannon Claude 31 August 1955 A Proposal for the Dartmouth Summer Research Project on Artificial Intelligence retrieved 16 October 2008 McCarthy John Hayes P J 1969 Some philosophical problems from the standpoint of artificial intelligence in Meltzer B J Mitchie Donald eds Machine Intelligence 4 Edinburgh University Press pp463502 retrieved 16 October 2008 McCorduck Pamela 2004 Machines Who Think 2nd ed Natick MA A K Peters Ltd ISBN 9781568812052 OCLC 52197627 McCullough W S Pitts W 1943 A logical calculus of the ideas immanent in nervous activity Bulletin of Mathematical Biophysics 5 4 115127 doi 101007BF02478259 Menabrea Luigi Federico Lovelace Ada 1843 Sketch of the Analytical Engine Invented by Charles Babbage Scientific Memoirs 3 retrieved 29 August 2008 With notes upon the Memoir by the Translator Minsky Marvin 1967 Computation Finite and Infinite Machines Englewood Cliffs NJ PrenticeHall Minsky Marvin Papert Seymour 1969 Perceptrons An Introduction to Computational Geometry The MIT Press ISBN 9780262631112 OCLC 16924756 Minsky Marvin 1974 A Framework for Representing Knowledge retrieved 16 October 2008 Minsky Marvin 1986 The Society of Mind Simon and Schuster ISBN 9780671657130 OCLC 223353010 Minsky Marvin 2001 Its 2001 Where Is HAL Dr Dobbs Technetcast retrieved 8 August 2009 Moravec Hans 1976 The Role of Raw Power in Intelligence retrieved 16 October 2008 Moravec Hans 1988 Mind Children Harvard University Press ISBN 9780674576186 OCLC 245755104 NRC 1999 Developments in Artificial Intelligence Funding a Revolution Government Support for Computing Research National Academy Press ISBN 9780309062787 OCLC 246584055 Newell Allen Simon H A 1963 GPS A Program that Simulates Human Thought in Feigenbaum EA Feldman J eds Computers and Thought New York McGrawHill ISBN 9780262560924 OCLC 246968117 Newquist HP 1994 The Brain Makers Genius Ego And Greed In The Quest For Machines That Think New York MacmillanSAMS ISBN 9780988593718 Nick Martin 2005 Al Jazari The Ingenious 13th Century Muslim Mechanic Al Shindagah retrieved 16 October 2008 OConnor Kathleen Malone 1994 The alchemical creation of life takwin and other concepts of Genesis in medieval Islam University of Pennsylvania pp1435 retrieved 10 January 2007 Olsen Stefanie 10 May 2004 Newsmaker Googles man behind the curtain CNET retrieved 17 October 2008 Olsen Stefanie 18 August 2006 Spying an intelligent search engine CNET retrieved 17 October 2008 Pearl J 1988 Probabilistic Reasoning in Intelligent Systems Networks of Plausible Inference San Mateo California Morgan Kaufmann ISBN 9781558604797 OCLC 249625842 Russell Stuart J Norvig Peter 2003 Artificial Intelligence A Modern Approach 2nd ed Upper Saddle River New Jersey Prentice Hall ISBN 0137903952 Poole David Mackworth Alan Goebel Randy 1998 Computational Intelligence A Logical Approach Oxford University Press ISBN 9780195102703 Samuel Arthur L July 1959 Some studies in machine learning using the game of checkers IBM Journal of Research and Development 3 3 210219 CiteSeerX 10113682254 doi 101147rd330210 retrieved 20 August 2007 Searle John 1980 Minds Brains and Programs Behavioral and Brain Sciences 3 3 417457 doi 101017S0140525X00005756 retrieved 13 May 2009 Simon H A Newell Allen 1958 Heuristic Problem Solving The Next Advance in Operations Research Operations Research 6 1 doi 101287opre611 Simon H A 1965 The Shape of Automation for Men and Management New York Harper Row Skillings Jonathan 2006 Newsmaker Getting machines to think like us CNET retrieved 8 October 2008 Tascarella Patty 14 August 2006 Robotics firms find fundraising struggle with venture capital shy Pittsburgh Business Times retrieved 15 March 2016 Turing Alan 193637 On Computable Numbers with an Application to the Entscheidungsproblem Proceedings of the London Mathematical Society 2 42 230265 doi 101112plmss2421230 retrieved 8 October 2008 Turing Alan October 1950 Computing Machinery and Intelligence Mind LIX 236 433460 doi 101093mindLIX236433 ISSN 00264423 Weizenbaum Joseph 1976 Computer Power and Human Reason WH Freeman Company ISBN 9780140225358 OCLC 10952283 