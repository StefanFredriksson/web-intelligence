Ethics of artificial intelligence Artificial intelligence Major goals Knowledge reasoning Planning Machine learning Natural language processing Computer vision Robotics Artificial general intelligence Approaches Symbolic Deep learning Bayesian networks Evolutionary algorithms Philosophy Ethics Existential risk Turing test Chinese room Control problem Friendly AI History Timeline Progress AI winter Technology Applications Projects Programming languages Glossary Glossary v t e The ethics of artificial intelligence is the part of the ethics of technology specific to robots and other artificially intelligent beings It is typically citation needed divided into roboethics a concern with the moral behavior of humans as they design construct use and treat artificially intelligent beings and machine ethics which is concerned with the moral behavior of artificial moral agents AMAs Contents 1 Robot ethics 11 Robot rights 12 Threat to human dignity 13 Transparency accountability and open source 2 Biases in AI systems 3 Liability for Partial or Fully Automated Cars 4 Weaponization of artificial intelligence 5 Machine ethics 6 Unintended consequences 7 Organizations 8 In fiction 9 Literature 10 See also 11 Notes 12 External links Robot ethics edit Main article Robot ethics The term robot ethics sometimes roboethics refers to the morality of how humans design construct use and treat robots and other artificially intelligent beings 1 It considers both how artificially intelligent beings may be used to harm humans and how they may be used to benefit humans Robot rights edit Robot rights is the concept that people should have moral obligations towards their machines similar to human rights or animal rights 2 It has been suggested that robot rights such as a right to exist and perform its own mission could be linked to robot duty to serve human by analogy with linking human rights to human duties before society 3 These could include the right to life and liberty freedom of thought and expression and equality before the law 4 The issue has been considered by the Institute for the Future 5 and by the UK Department of Trade and Industry 6 Experts disagree whether specific and detailed laws will be required soon or safely in the distant future 6 Glenn McGee reports that sufficiently humanoid robots may appear by 2020 7 Ray Kurzweil sets the date at 2029 8 Another group of scientists meeting in 2007 supposed that at least 50 years had to pass before any sufficiently advanced system would exist 9 The rules for the 2003 Loebner Prize competition envisioned the possibility of robots having rights of their own 61 If in any given year a publicly available open source Entry entered by the University of Surrey or the Cambridge Center wins the Silver Medal or the Gold Medal then the Medal and the Cash Award will be awarded to the body responsible for the development of that Entry If no such body can be identified or if there is disagreement among two or more claimants the Medal and the Cash Award will be held in trust until such time as the Entry may legally possess either in the United States of America or in the venue of the contest the Cash Award and Gold Medal in its own right 10 In October 2017 the android Sophia was granted honorary citizenship in Saudi Arabia though some observers found this to be more of a publicity stunt than a meaningful legal recognition 11 Some saw this gesture as openly denigrating of human rights and the rule of law 12 The philosophy of Sentientism grants degrees of moral consideration to all sentient beings primarily humans and most nonhuman animals If artificial or alien intelligences show evidence of being sentient this philosophy holds that they should be shown compassion and granted rights Joanna Bryson has argued that creating AI that requires rights is both avoidable and would in itself be unethical both as a burden to the AI agents and to human society 13 Threat to human dignity edit Main article Computer Power and Human Reason Joseph Weizenbaum argued in 1976 that AI technology should not be used to replace people in positions that require respect and care such as any of these A customer service representative AI technology is already used today for telephonebased interactive voice response systems A therapist as was proposed by Kenneth Colby in the 1970s A nursemaid for the elderly as was reported by Pamela McCorduck in her book The Fifth Generation A soldier A judge A police officer Weizenbaum explains that we require authentic feelings of empathy from people in these positions If machines replace them we will find ourselves alienated devalued and frustrated Artificial intelligence if used in this way represents a threat to human dignity Weizenbaum argues that the fact that we are entertaining the possibility of machines in these positions suggests that we have experienced an atrophy of the human spirit that comes from thinking of ourselves as computers 14 Pamela McCorduck counters that speaking for women and minorities Id rather take my chances with an impartial computer pointing out that there are conditions where we would prefer to have automated judges and police that have no personal agenda at all 14 However Kaplan and Haenlein stress that AI systems are only as smart as the data used to train them since they are in their essence nothing more than fancy curvefitting machines Using AI to support a court ruling can be highly problematic if past rulings show bias toward certain groups since those biases get formalized and engrained which makes them even more difficult to spot and fight against 15 AI founder John McCarthy objects to the moralizing tone of Weizenbaums critique When moralizing is both vehement and vague it invites authoritarian abuse he writes Bill Hibbard 16 writes that Human dignity requires that we strive to remove our ignorance of the nature of existence and AI is necessary for that striving Transparency accountability and open source edit Bill Hibbard argues that because AI will have such a profound effect on humanity AI developers are representatives of future humanity and thus have an ethical obligation to be transparent in their efforts 17 Ben Goertzel and David Hart created OpenCog as an open source framework for AI development 18 OpenAI is a nonprofit AI research company created by Elon Musk Sam Altman and others to develop open source AI beneficial to humanity 19 There are numerous other open source AI developments Unfortunately making code open source does not make it comprehensible which by many definitions means that the AI it codes is not transparent The IEEE has a standardisation effort on AI transparency 20 The IEEE effort identifies multiple scales of transparency for different users Further there is concern that releasing the full capacity of contemporary AI to some organisations may be a public bad that is do more damage than good For example Microsoft has expressed concern about allowing universal access to its face recognition software even for those who can pay for it Microsoft posted an extraordinary blog on this topic asking for government regulation to help determine the right thing to do 21 Not only companies but many other researchers and citizen advocates recommend government regulation as a means of ensuring transparency and through it human accountability An updated collection list of AI Ethics is maintained by AlgorithmWatch This strategy has proven controversial as some worry that it will slow the rate of innovation Others argue that regulation leads to systemic stability more able to support innovation in the long term 22 The OECD UN EU and many countries are presently working on strategies for regulating AI and finding appropriate legal frameworks 23 24 25 On June 26 the European Commission HighLevel Expert Group on Artificial Intelligence AI HLEG published its Policy and investment recommendations for trustworthy Artificial Intelligence This is the second deliverable of the AI HLEG and follows the April 2019 publication of the groups Ethics Guidelines for Trustworthy AI The new recommendations focus on four main areas humans and society at large the private sector the public sector and research and academia The HLEGs recommendations reflect an appreciation of both the opportunities for AI technologies to drive economic growth prosperity and innovation as well as the potential risks involved The European Union has an ambition to lead the framing of policies governing AI globally However unless Europe accelerates deployment and uptake and builds industrial research and development capabilities its ability to do so will be limited 26 Biases in AI systems edit AI has become increasingly inherent in facial and voice recognition systems Some of these systems have real business implications and directly impact people These systems are vulnerable to biases and errors introduced by its human makers Also the data used to train these AI systems itself can have biases 27 28 29 30 For instance facial recognition algorithms made by Microsoft IBM and Face all had biases when it came to detecting peoples gender 31 These AI systems were able to detect gender of white men more accurately than gender of darker skin men Similarly Amazonscom Incs termination of AI hiring and recruitment is another example which exhibit AI cannot be fair The algorithm preferred more male candidates than female This was because Amazons system was trained with data collected over 10year period that came mostly from male candidates 32 Bias can creep into algorithms in many ways For example Friedman and Nissenbaum identify three categories of bias in computer systems existing bias technical bias and emergent bias 33 In a highly influential branch of AI known as natural language processing problems can arise from the text corpusthe source material the algorithm uses to learn about the relationships between different words 34 Large companies such as IBM Google etc started researching and addressing bias 35 36 37 One solution for addressing bias is to create documentation for the data used to train AI systems 38 The problem of bias in machine learning is likely to become more significant as the technology spreads to critical areas like medicine and law and as more people without a deep technical understanding are tasked with deploying it Some experts warn that algorithmic bias is already pervasive in many industries and that almost no one is making an effort to identify or correct it 39 Liability for Partial or Fully Automated Cars edit The wide use of partial to fully autonomous cars seems to be imminent in the future But fully autonomous technologies present new issues and challenges 40 41 42 Recently a debate over the legal liability have risen over the responsible party if these cars get into accidents 43 44 In one of the reports 45 a driverless car hit a pedestrian and had a dilemma over whom to blame for the accident Even though the driver was inside the car during the accident the controls were fully in the hand of computers In one case that took place on March 19 2018 a selfdriving Uber Car kills pedestrian in Arizona Death of Elaine Herzberg which alternatively leads to the death of that jaywalking pedestrian Without further investigate on how did the pedestrian got injurydeath in such case It is important for people to reconsider the liability not only for those partial or fully automated cars but those stakeholder who should be responsible for such situation as well In this case the automated cars have the function of detecting nearby possible cars and objects in order to run the function of selfdriven but it did not have the ability to react to nearby pedestrian within its original function due to the fact that there will not be people appear on the road in a normal sense This leads the issue of whether the driver pedestrian the car company or the government should be responsible in such case According this article 46 with the current partial or fully automated cars function are still amateur which still require driver to pay attention with fully control the vehicle since all these functionsfeature are just supporting driver to be less tried while they driving but not let go Thus the government should be most responsible for current situation on how they should regulate the car company and driver who are overrely on selfdriven feature as well educated them that these are just technologies that bring convenience to people life but not a shortcut Before autonomous cars become widely used these issues need to be tackled through new policies 47 48 49 Weaponization of artificial intelligence edit Main article Lethal autonomous weapon Some experts and academics have questioned the use of robots for military combat especially when such robots are given some degree of autonomous functions 50 51 The US Navy has funded a report which indicates that as military robots become more complex there should be greater attention to implications of their ability to make autonomous decisions 52 53 One researcher states that autonomous robots might be more humane as they could make decisions more effectively citation needed Within this last decade there has been intensive research in autonomous power with the ability to learn using assigned moral responsibilities The results may be used when designing future military robots to control unwanted tendencies to assign responsibility to the robots 54 From a consequentialist view there is a chance that robots will develop the ability to make their own logical decisions on who to kill and that is why there should be a set moral framework that the AI cannot override 55 There has been a recent outcry with regard to the engineering of artificialintelligence weapons that has included ideas of a robot takeover of mankind AI weapons do present a type of danger different from that of humancontrolled weapons Many governments have begun to fund programs to develop AI weaponry The United States Navy recently announced plans to develop autonomous drone weapons paralleling similar announcements by Russia and Korea respectively Due to the potential of AI weapons becoming more dangerous than humanoperated weapons Stephen Hawking and Max Tegmark signed a Future of Life petition 56 to ban AI weapons The message posted by Hawking and Tegmark states that AI weapons pose an immediate danger and that action is required to avoid catastrophic disasters in the near future 57 If any major military power pushes ahead with the AI weapon development a global arms race is virtually inevitable and the endpoint of this technological trajectory is obvious autonomous weapons will become the Kalashnikovs of tomorrow says the petition which includes Skype cofounder Jaan Tallinn and MIT professor of linguistics Noam Chomsky as additional supporters against AI weaponry 58 Physicist and Astronomer Royal Sir Martin Rees has warned of catastrophic instances like dumb robots going rogue or a network that develops a mind of its own Huw Price a colleague of Rees at Cambridge has voiced a similar warning that humans might not survive when intelligence escapes the constraints of biology These two professors created the Centre for the Study of Existential Risk at Cambridge University in the hope of avoiding this threat to human existence 57 Regarding the potential for smarterthanhuman systems to be employed militarily the Open Philanthropy Project writes that these scenarios seem potentially as important as the risks related to loss of control but that research organizations investigating AIs longrun social impact have spent relatively little time on this concern this class of scenarios has not been a major focus for the organizations that have been most active in this space such as the Machine Intelligence Research Institute MIRI and the Future of Humanity Institute FHI and there seems to have been less analysis and debate regarding them 59 Machine ethics edit Main article Machine ethics Machine ethics or machine morality is the field of research concerned with designing Artificial Moral Agents AMAs robots or artificially intelligent computers that behave morally or as though moral 60 61 62 63 To account for the nature of these agents it has been suggested to consider certain philosophical ideas like the standard characterizations of agency rational agency moral agency and artificial agency which are related to the concept of AMAs 64 Isaac Asimov considered the issue in the 1950s in his I Robot At the insistence of his editor John W Campbell Jr he proposed the Three Laws of Robotics to govern artificially intelligent systems Much of his work was then spent testing the boundaries of his three laws to see where they would break down or where they would create paradoxical or unanticipated behavior His work suggests that no set of fixed laws can sufficiently anticipate all possible circumstances 65 More recently academics and many governments have challenged the idea that AI can itself be held accountable 66 A panel convened by the United Kingdom in 2010 revised Asimovs laws to clarify that AI is the responsibility either of its manufacturers or of its owneroperator 67 In 2009 during an experiment at the Laboratory of Intelligent Systems in the Ecole Polytechnique Fédérale of Lausanne in Switzerland robots that were programmed to cooperate with each other in searching out a beneficial resource and avoiding a poisonous one eventually learned to lie to each other in an attempt to hoard the beneficial resource 68 One problem in this case may have been that the goals were terminal ie in contrast ultimate human motives typically have a quality of requiring neverending learning 69 Some experts and academics have questioned the use of robots for military combat especially when such robots are given some degree of autonomous functions 50 The US Navy has funded a report which indicates that as military robots become more complex there should be greater attention to implications of their ability to make autonomous decisions 70 71 The President of the Association for the Advancement of Artificial Intelligence has commissioned a study to look at this issue 72 They point to programs like the Language Acquisition Device which can emulate human interaction Vernor Vinge has suggested that a moment may come when some computers are smarter than humans He calls this the Singularity 73 He suggests that it may be somewhat or possibly very dangerous for humans 74 This is discussed by a philosophy called Singularitarianism The Machine Intelligence Research Institute has suggested a need to build Friendly AI meaning that the advances which are already occurring with AI should also include an effort to make AI intrinsically friendly and humane 75 In 2009 academics and technical experts attended a conference organized by the Association for the Advancement of Artificial Intelligence to discuss the potential impact of robots and computers and the impact of the hypothetical possibility that they could become selfsufficient and able to make their own decisions They discussed the possibility and the extent to which computers and robots might be able to acquire any level of autonomy and to what degree they could use such abilities to possibly pose any threat or hazard They noted that some machines have acquired various forms of semiautonomy including being able to find power sources on their own and being able to independently choose targets to attack with weapons They also noted that some computer viruses can evade elimination and have achieved cockroach intelligence They noted that selfawareness as depicted in sciencefiction is probably unlikely but that there were other potential hazards and pitfalls 73 However there is one technology in particular that could truly bring the possibility of robots with moral competence to reality In a paper on the acquisition of moral values by robots Nayef AlRodhan mentions the case of neuromorphic chips which aim to process information similarly to humans nonlinearly and with millions of interconnected artificial neurons 76 Robots embedded with neuromorphic technology could learn and develop knowledge in a uniquely humanlike way Inevitably this raises the question of the environment in which such robots would learn about the world and whose morality they would inherit or if they end up developing human weaknesses as well selfishness a prosurvival attitude hesitation etc In Moral Machines Teaching Robots Right from Wrong 77 Wendell Wallach and Colin Allen conclude that attempts to teach robots right from wrong will likely advance understanding of human ethics by motivating humans to address gaps in modern normative theory and by providing a platform for experimental investigation As one example it has introduced normative ethicists to the controversial issue of which specific learning algorithms to use in machines Nick Bostrom and Eliezer Yudkowsky have argued for decision trees such as ID3 over neural networks and genetic algorithms on the grounds that decision trees obey modern social norms of transparency and predictability eg stare decisis 78 while Chris SantosLang argued in the opposite direction on the grounds that the norms of any age must be allowed to change and that natural failure to fully satisfy these particular norms has been essential in making humans less vulnerable to criminal hackers 69 According to a 2019 report from the Center for the Governance of AI at the University of Oxford 82 of Americans believe that robots and AI should be carefully managed Concerns cited ranged from how AI is used in surveillance and in spreading fake content online known as deepfakes when they include doctored video images and audio generated with help from AI to cyberattacks infringements on data privacy hiring bias autonomous vehicles and drones that dont require a human controller 79 Unintended consequences edit Further information Existential risk from artificial general intelligence Many researchers have argued that by way of an intelligence explosion sometime in the 21st century a selfimproving AI could become so vastly more powerful than humans that we would not be able to stop it from achieving its goals 80 In his paper Ethical Issues in Advanced Artificial Intelligence philosopher Nick Bostrom argues that artificial intelligence has the capability to bring about human extinction He claims that general superintelligence would be capable of independent initiative and of making its own plans and may therefore be more appropriately thought of as an autonomous agent Since artificial intellects need not share our human motivational tendencies it would be up to the designers of the superintelligence to specify its original motivations In theory a superintelligent AI would be able to bring about almost any possible outcome and to thwart any attempt to prevent the implementation of its top goal many uncontrolled unintended consequences could arise It could kill off all other agents persuade them to change their behavior or block their attempts at interference 81 However instead of overwhelming the human race and leading to our destruction Bostrom has also asserted that superintelligence can help us solve many difficult problems such as disease poverty and environmental destruction and could help us to enhance ourselves 82 The sheer complexity of human value systems makes it very difficult to make AIs motivations humanfriendly 80 81 Unless moral philosophy provides us with a flawless ethical theory an AIs utility function could allow for many potentially harmful scenarios that conform with a given ethical framework but not common sense According to Eliezer Yudkowsky there is little reason to suppose that an artificially designed mind would have such an adaptation 83 Bill Hibbard 16 proposes an AI design that avoids several types of unintended AI behavior including selfdelusion unintended instrumental actions and corruption of the reward generator Organizations edit This section needs expansion You can help by adding to it May 2018 Amazon Google Facebook IBM and Microsoft have established a nonprofit partnership to formulate best practices on artificial intelligence technologies advance the publics understanding and to serve as a platform about artificial intelligence They stated This partnership on AI will conduct research organize discussions provide thought leadership consult with relevant third parties respond to questions from the public and media and create educational material that advance the understanding of AI technologies including machine perception learning and automated reasoning 84 Apple joined other tech companies as a founding member of the Partnership on AI in January 2017 The corporate members will make financial and research contributions to the group while engaging with the scientific community to bring academics onto the board 85 The Public Voice has proposed in late 2018 a set of Universal Guidelines for Artificial Intelligence which has received many notable endorsements The IEEE put together a Global Initiative on Ethics of Autonomous and Intelligent Systems which has been creating and revising guidelines with the help of public input and accepts as members many professionals from within and without its organisation Traditionally government has been used by societies to ensure ethics are observed through legislation and policing There are now many efforts by national governments as well as transnational government and nongovernment organisations to ensure AI is ethically applied The European Commission has a HighLevel Expert Group on Artificial Intelligence The OECD on Artificial Intelligence In the United States the Obama administration put together a Roadmap for AI Policy link is to Harvard Business Review s account of it The Obama Administration released two prominent whitepapers on the future and impact of AI The Trump administration has not been actively engaged in AI regulation to date January 2019 The Computing Community Consortium CCC weighed in with a 100plus page draft report 86 A 20Year Community Roadmap for Artificial Intelligence Research in the US 87 In fiction edit Main article Artificial intelligence in fiction The movie The Thirteenth Floor suggests a future where simulated worlds with sentient inhabitants are created by computer game consoles for the purpose of entertainment The movie The Matrix suggests a future where the dominant species on planet Earth are sentient machines and humanity is treated with utmost Speciesism The short story The Planck Dive suggest a future where humanity has turned itself into software that can be duplicated and optimized and the relevant distinction between types of software is sentient and nonsentient The same idea can be found in the Emergency Medical Hologram of Starship Voyager which is an apparently sentient copy of a reduced subset of the consciousness of its creator Dr Zimmerman who for the best motives has created the system to give medical assistance in case of emergencies The movies Bicentennial Man and AI deal with the possibility of sentient robots that could love I Robot explored some aspects of Asimovs three laws All these scenarios try to foresee possibly unethical consequences of the creation of sentient computers citation needed The ethics of artificial intelligence is one of several core themes in BioWares Mass Effect series of games citation needed It explores the scenario of a civilization accidentally creating AI through a rapid increase in computational power through a global scale neural network This event caused an ethical schism between those who felt bestowing organic rights upon the newly sentient Geth was appropriate and those who continued to see them as disposable machinery and fought to destroy them Beyond the initial conflict the complexity of the relationship between the machines and their creators is another ongoing theme throughout the story Over time debates have tended to focus less and less on possibility and more on desirability citation needed as emphasized in the Cosmist and Terran debates initiated by Hugo de Garis and Kevin Warwick A Cosmist according to Hugo de Garis is actually seeking to build more intelligent successors to the human species Literature edit The standard bibliography on ethics of AI is on PhilPapers A recent collection is VC Müllered 2016 88 See also edit Algorithmic bias Artificial consciousness Artificial general intelligence AGI Computer ethics Effective altruism the long term future and global catastrophic risks Existential risk from artificial general intelligence Laws of Robotics Philosophy of artificial intelligence Roboethics Robotic Governance Superintelligence Paths Dangers Strategies Researchers Nick Bostrom Joanna Bryson Luciano Floridi Ray Kurzweil Vincent C Müller Peter Norvig Steve Omohundro Stuart J Russell Anders Sandberg Eliezer Yudkowsky Organisations Centre for the Study of Existential Risk Future of Humanity Institute Future of Life Institute Machine Intelligence Research Institute Partnership on AI Notes edit Veruggio Gianmarco 2007 The Roboethics Roadmap Scuola di Robotica 2 CiteSeerX 10114662810 Cite journal requires journal help mwparseroutput citecitationfontstyleinheritmwparseroutput citation qquotesmwparseroutput idlockfree amwparseroutput citation cs1lockfree abackgroundurluploadwikimediaorgwikipediacommonsthumb665Lockgreensvg9pxLockgreensvgpngnorepeatbackgroundpositionright 1em centermwparseroutput idlocklimited amwparseroutput idlockregistration amwparseroutput citation cs1locklimited amwparseroutput citation cs1lockregistration abackgroundurluploadwikimediaorgwikipediacommonsthumbdd6Lockgrayalt2svg9pxLockgrayalt2svgpngnorepeatbackgroundpositionright 1em centermwparseroutput idlocksubscription amwparseroutput citation cs1locksubscription abackgroundurluploadwikimediaorgwikipediacommonsthumbaaaLockredalt2svg9pxLockredalt2svgpngnorepeatbackgroundpositionright 1em centermwparseroutput cs1subscriptionmwparseroutput cs1registrationcolor555mwparseroutput cs1subscription spanmwparseroutput cs1registration spanborderbottom1px dottedcursorhelpmwparseroutput cs1wsicon abackgroundurluploadwikimediaorgwikipediacommonsthumb44cWikisourcelogosvg12pxWikisourcelogosvgpngnorepeatbackgroundpositionright 1em centermwparseroutput codecs1codecolorinheritbackgroundinheritborderinheritpaddinginheritmwparseroutput cs1hiddenerrordisplaynonefontsize100mwparseroutput cs1visibleerrorfontsize100mwparseroutput cs1maintdisplaynonecolor33aa33marginleft03emmwparseroutput cs1subscriptionmwparseroutput cs1registrationmwparseroutput cs1formatfontsize95mwparseroutput cs1kernleftmwparseroutput cs1kernwlleftpaddingleft02emmwparseroutput cs1kernrightmwparseroutput cs1kernwlrightpaddingright02em Evans Woody 2015 Posthuman Rights Dimensions of Transhuman Worlds Teknokultura 12 2 doi 105209revTK2015v12n249072 Sheliazhenko Yurii 2017 Artificial Personal Autonomy and Concept of Robot Rights European journal of law and political sciences Retrieved 10 May 2017 Cite journal requires journal help The American Heritage Dictionary of the English Language Fourth Edition Robots could demand legal rights BBC News December 21 2006 Retrieved January 3 2010 a b Henderson Mark April 24 2007 Human rights for robots Were getting carried away The Times Online The Times of London Retrieved May 2 2010 McGee Glenn A Robot Code of Ethics The Scientist Kurzweil Ray 2005 The Singularity is Near Penguin Books ISBN 9780670033843 The Big Question Should the human race be worried by the rise of robots Independent Newspaper Loebner Prize Contest Official Rules Version 20 The competition was directed by David Hamill and the rules were developed by members of the Robitron Yahoo group Saudi Arabia bestows citizenship on a robot named Sophia Vincent James 30 October 2017 Pretending to give a robot citizenship helps no one The Verge Close engagements with artificial companions key social psychological ethical and design issues Wilks Yorick 1939 Amsterdam John Benjamins Pub Co 2010 ISBN 9789027249944 OCLC 642206106 CS1 maint others link a b Joseph Weizenbaum quoted in McCorduck 2004 pp356 374376 Kaplan Andreas Michael Haenlein 2018 Siri Siri in my Hand whos the Fairest in the Land On the Interpretations Illustrations and Implications of Artificial Intelligence Business Horizons 621 Archived from the original on 20181121 Retrieved 20181127 a b Hibbard Bill 2014 Ethical Artificial Intelligence Open Source AI Bill Hibbard 2008 proceedings of the First Conference on Artificial General Intelligence eds Pei Wang Ben Goertzel and Stan Franklin OpenCog A Software Framework for Integrative Artificial General Intelligence David Hart and Ben Goertzel 2008 proceedings of the First Conference on Artificial General Intelligence eds Pei Wang Ben Goertzel and Stan Franklin Inside OpenAI Elon Musks Wild Plan to Set Artificial Intelligence Free Cade Metz Wired 27 April 2016 P7001 Transparency of Autonomous Systems P7001 Transparency of Autonomous Systems IEEE Retrieved 10 January 2019 Thurm Scott July 13 2018 MICROSOFT CALLS FOR FEDERAL REGULATION OF FACIAL RECOGNITION Wired Bastin Roland Wantz Georges June 2017 The General Data Protection Regulation Crossindustry innovation PDF Inside magazine Deloitte UN artificial intelligence summit aims to tackle poverty humanitys grand challenges UN News 20170607 Retrieved 20190726 Artificial intelligence Organisation for Economic Cooperation and Development wwwoecdorg Retrieved 20190726 Anonymous 20180614 The European AI Alliance Digital Single Market European Commission Retrieved 20190726 EU Tech Policy Brief July 2019 Recap Center for Democracy Technology Retrieved 20190809 Society DeepMind Ethics 20180314 The case for fairer algorithms DeepMind Ethics Society Medium Retrieved 20190722 5 unexpected sources of bias in artificial intelligence TechCrunch Retrieved 20190722 Knight Will Googles AI chief says forget Elon Musks killer robots and worry about bias in AI systems instead MIT Technology Review Retrieved 20190722 Villasenor John 20190103 Artificial intelligence and bias Four key challenges Brookings Retrieved 20190722 Lohr Steve 20180209 Facial Recognition Is Accurate if Youre a White Guy The New York Times ISSN 03624331 Retrieved 20190529 Amazon scraps secret AI recruiting tool that showed bias against women Reuters 20181010 Retrieved 20190529 Friedman Batya Nissenbaum Helen 19960701 Bias in computer systems ACM Transactions on Information Systems 14 3 330347 doi 101145230538230561 ISSN 10468188 Eliminating bias in AI techxplorecom Retrieved 20190726 Olson Parmy Googles DeepMind Has An Idea For Stopping Biased AI Forbes Retrieved 20190726 Machine Learning Fairness ML Fairness Google Developers Retrieved 20190726 AI and bias IBM Research US wwwresearchibmcom REPLACE Retrieved 20190726 Check date values in date help Bender Emily M Friedman Batya December 2018 Data Statements for Natural Language Processing Toward Mitigating System Bias and Enabling Better Science Transactions of the Association for Computational Linguistics 6 587604 doi 101162tacla00041 ISSN 2307387X Knight Will Googles AI chief says forget Elon Musks killer robots and worry about bias in AI systems instead MIT Technology Review Retrieved 20190726 Davies Alex 20160229 Googles SelfDriving Car Caused Its First Crash Wired ISSN 10591028 Retrieved 20190726 List of selfdriving car fatalities Wikipedia 20190605 retrieved 20190726 Levin Sam Wong Julia Carrie 20180319 Selfdriving Uber kills Arizona woman in first fatal crash involving pedestrian The Guardian ISSN 02613077 Retrieved 20190726 Who is responsible when a selfdriving car has an accident Futurism Retrieved 20190726 Radio Business Policy Law and Public Podcasts America North Autonomous Car Crashes Who or What Is to Blame KnowledgeWharton Retrieved 20190726 Delbridge Emily Driverless Cars Gone Wild The Balance Retrieved 20190529 Maxmen Amy 20181024 Selfdriving car dilemmas reveal that moral choices are not universal Nature 562 7728 469470 doi 101038d41586018071350 Regulations for driverless cars GOVUK Retrieved 20190726 Automated Driving Legislative and Regulatory Action CyberWiki cyberlawstanfordedu Retrieved 20190726 Autonomous Vehicles SelfDriving Vehicles Enacted Legislation wwwncslorg Retrieved 20190726 a b Call for debate on killer robots By Jason Palmer Science and technology reporter BBC News 8309 Robot ThreeWay Portends Autonomous Future By David Axe wiredcom August 13 2009 New Navyfunded Report Warns of War Robots Going Terminator Archived 20090728 at the Wayback Machine by Jason Mick Blog dailytechcom February 17 2009 Navy report warns of robot uprising suggests a strong moral compass by Joseph L Flatley engadgetcom Feb 18th 2009 httpssearchproquestcomdocview1372020233 Mitra Ambarish We can train AI to identify good and evil and then use it to teach us morality Quartz Retrieved 20190726 AI Principles Future of Life Institute Retrieved 20190726 a b Zach Musgrave and Bryan W Roberts 20150814 Why Artificial Intelligence Can Too Easily Be Weaponized The Atlantic The Atlantic Cat Zakrzewski 20150727 Musk Hawking Warn of Artificial Intelligence Weapons WSJ GiveWell 2015 Potential risks from advanced artificial intelligence Report Retrieved 11 October 2015 Anderson Machine Ethics Retrieved 27 June 2011 Anderson Michael Anderson Susan Leigh eds July 2011 Machine Ethics Cambridge University Press ISBN 9780521112352 Anderson Michael Anderson Susan Leigh eds JulyAugust 2006 Special Issue on Machine Ethics IEEE Intelligent Systems 21 4 1063 doi 101109mis200670 ISSN 15411672 Archived from the original on 20111126 Anderson Michael Anderson Susan Leigh Winter 2007 Machine Ethics Creating an Ethical Intelligent Agent AI Magazine 28 4 1526 ISSN 07384602 Boyles Robert James M October 2017 Philosophical Signposts for Artificial Moral Agent Frameworks PDF Suri 6 2 92109 Asimov Isaac 2008 I Robot New York Bantam ISBN 9780553382563 Bryson Joanna Diamantis Mihailis Grant Thomas September 2017 Of for and by the people the legal lacuna of synthetic persons Artificial Intelligence and Law 25 3 273291 doi 101007s1050601792149 Principles of robotics UKs EPSRC September 2010 Retrieved 10 January 2019 Evolving Robots Learn To Lie To Each Other Popular Science August 18 2009 a b SantosLang Chris 2002 Ethics for Artificial Intelligences Science New Navyfunded Report Warns of War Robots Going Terminator Archived 20090728 at the Wayback Machine by Jason Mick Blog dailytechcom February 17 2009 Navy report warns of robot uprising suggests a strong moral compass by Joseph L Flatley engadgetcom Feb 18th 2009 AAAI Presidential Panel on LongTerm AI Futures 20082009 Study Association for the Advancement of Artificial Intelligence Accessed 72609 a b Scientists Worry Machines May Outsmart Man By JOHN MARKOFF NY Times July 26 2009 The Coming Technological Singularity How to Survive in the PostHuman Era by Vernor Vinge Department of Mathematical Sciences San Diego State University c 1993 by Vernor Vinge Article at Asimovlawscom Archived May 24 2012 at the Wayback Machine July 2004 accessed 72709 AlRodhan Nayef 20150812 The Moral Code Foreign Affairs ISSN 00157120 Retrieved 20180123 Wallach Wendell Allen Colin November 2008 Moral Machines Teaching Robots Right from Wrong USA Oxford University Press ISBN 9780195374049 Bostrom Nick Yudkowsky Eliezer 2011 The Ethics of Artificial Intelligence PDF Cambridge Handbook of Artificial Intelligence Cambridge Press Howard Ayanna The Regulation of AI Should Organizations Be Worried Ayanna Howard MIT Sloan Management Review Retrieved 20190814 a b Muehlhauser Luke and Louie Helm 2012 Intelligence Explosion and Machine Ethics In Singularity Hypotheses A Scientific and Philosophical Assessment edited by Amnon Eden Johnny Søraker James H Moor and Eric Steinhart Berlin Springer a b Bostrom Nick 2003 Ethical Issues in Advanced Artificial Intelligence In Cognitive Emotive and Ethical Aspects of Decision Making in Humans and in Artificial Intelligence edited by Iva Smit and George E Lasker 1217 Vol 2 Windsor ON International Institute for Advanced Studies in Systems Research Cybernetics Sure Artificial Intelligence May End Our World But That Is Not the Main Problem WIRED 20141204 Retrieved 20151104 Yudkowsky Eliezer 2011 Complex Value Systems in Friendly AI In Schmidhuber Thórisson and Looks 2011 388393 Partnership on Artificial Intelligence to Benefit People and Society Np nd 24 October 2016 Fiegerman Seth Facebook Google Amazon Create Group to Ease AI Concerns CNNMoney nd 4 December 2016 CCC Offers Draft 20Year AI Roadmap Seeks Comments HPCwire 20190514 Retrieved 20190722 Request Comments on Draft A 20Year Community Roadmap for AI Research in the US CCC Blog Retrieved 20190722 Müller Vincent C 2016 Risks of artificial intelligence CRC Press Chapman Hall External links edit Robotics Ethics of artificial intelligence Four leading researchers share their concerns and solutions for reducing societal risks from intelligent machines Nature 521 415418 28 May 2015 doi101038521415a BBC News Games to take on a life of their own Whos Afraid of Robots an article on humanitys fear of artificial intelligence A short history of computer ethics AI Ethics Guidelines Global Inventory by Algorithmwatch The Ethics of AI Ethics An Evaluation of Guidelines an overview and evaluation of AI ethics guidelines v t e Philosophy of science Concepts Analysis Analyticsynthetic distinction A priori and a posteriori Causality Commensurability Consilience Construct Creative synthesis Demarcation problem Empirical evidence Explanatory power Fact Falsifiability Feminist method Functional contextualism Ignoramus et ignorabimus Inductive reasoning Intertheoretic reduction Inquiry Nature Objectivity Observation Paradigm Problem of induction Scientific law Scientific method Scientific revolution Scientific theory Testability Theory choice Theoryladenness Underdetermination Unity of science Metatheory of science Coherentism Confirmation holism Constructive empiricism Constructive realism Constructivist epistemology Contextualism Conventionalism Deductivenomological model Hypotheticodeductive model Inductionism Epistemological anarchism Evolutionism Fallibilism Foundationalism Instrumentalism Pragmatism Modeldependent realism Naturalism Physicalism Positivism Reductionism Determinism Rationalism Empiricism Received view Semantic view of theories Scientific realism Antirealism Scientific essentialism Scientific formalism Scientific skepticism Scientism Structuralism Uniformitarianism Vitalism Philosophy of Physics thermal and statistical Motion Chemistry Biology Environment Geography Social science Technology Engineering Artificial intelligence Computer science Information Mind Psychiatry Psychology Perception Space and time Related topics Alchemy Criticism of science Epistemology Faith and rationality History and philosophy of science History of science History of evolutionary thought Logic Metaphysics Pseudoscience Relationship between religion and science Rhetoric of science Science studies Sociology of scientific knowledge Sociology of scientific ignorance Philosophers of science by era Ancient Plato Aristotle Stoicism Epicureans Medieval Averroes Avicenna Roger Bacon William of Ockham Hugh of Saint Victor Dominicus Gundissalinus Robert Kilwardby Early modern Francis Bacon Thomas Hobbes René Descartes Galileo Galilei Pierre Gassendi Isaac Newton David Hume Late modern Immanuel Kant Friedrich Schelling William Whewell Auguste Comte John Stuart Mill Herbert Spencer Wilhelm Wundt Charles Sanders Peirce Wilhelm Windelband Henri Poincaré Pierre Duhem Rudolf Steiner Karl Pearson Contemporary Alfred North Whitehead Bertrand Russell Albert Einstein Otto Neurath C D Broad Michael Polanyi Hans Reichenbach Rudolf Carnap Karl Popper Carl Gustav Hempel W V O Quine Thomas Kuhn Imre Lakatos Paul Feyerabend Jürgen Habermas Ian Hacking Bas van Fraassen Larry Laudan Daniel Dennett Category Philosophy portal Science portal v t e Ethics Theories Casuistry Consequentialism Deontology Kantian ethics Ethics of care Existentialist ethics Metaethics Particularism Pragmatic ethics Role ethics Virtue ethics Concepts Autonomy Axiology Belief Conscience Consent Equality Care Free will Good and evil Good Evil Happiness Ideal Immorality Justice Liberty Morality Norm Freedom Principles Suffering or Pain Stewardship Sympathy Trust Value Virtue World view Wrong full index Philosophers Laozi Socrates Plato Aristotle Diogenes Valluvar Cicero Confucius Augustine of Hippo Mencius Mozi Xunzi Thomas Aquinas Baruch Spinoza David Hume Immanuel Kant Georg W F Hegel Arthur Schopenhauer Jeremy Bentham John Stuart Mill Søren Kierkegaard Henry Sidgwick Friedrich Nietzsche G E Moore Karl Barth Paul Tillich Dietrich Bonhoeffer Philippa Foot John Rawls John Dewey Bernard Williams J L Mackie G E M Anscombe William Frankena Alasdair MacIntyre R M Hare Peter Singer Derek Parfit Thomas Nagel Robert Merrihew Adams Charles Taylor Joxe Azurmendi Christine Korsgaard Martha Nussbaum more Applied ethics Bioethics Business ethics Discourse ethics Engineering ethics Environmental ethics Legal ethics Media ethics Medical ethics Nursing ethics Professional ethics Sexual ethics Ethics of eating meat Ethics of technology Metaethics Cognitivism Moral realism Ethical naturalism Ethical nonnaturalism Ethical subjectivism Ideal observer theory Divine command theory Error theory Noncognitivism Emotivism Quasirealism Universal prescriptivism Moral universalism Value monism Value pluralism Moral relativism Moral nihilism Empiricism Moral rationalism Ethical intuitionism Moral skepticism Related articles Christian ethics Descriptive ethics Ethics in religion Evolutionary ethics Feminist ethics History of ethics Ideology Islamic ethics Jewish ethics Moral psychology Normative ethics Philosophy of law Political philosophy Population ethics Social philosophy Category 