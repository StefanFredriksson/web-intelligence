Computer performance In computing computer performance is the amount of useful work accomplished by a computer system Outside of specific contexts computer performance is estimated in terms of accuracy efficiency and speed of executing computer program instructions When it comes to high computer performance one or more of the following factors might be involved Short response time for a given piece of work High throughput rate of processing work Low utilization of computing resource s High availability of the computing system or application Fast or highly compact data compression and decompression High bandwidth Short data transmission time Contents 1 Technical and nontechnical definitions 11 As an aspect of software quality 2 Performance engineering 21 Application performance engineering 3 Aspects of Performance 31 Availability 32 Response time 33 Processing speed 34 Channel capacity 35 Latency 36 Bandwidth 37 Throughput 38 Relative efficiency 39 Scalability 310 Power consumption 3101 Performance per watt 311 Compression ratio 312 Size and weight 313 Environmental impact 314 Transistor count 4 Benchmarks 5 Software performance testing 51 Profiling performance analysis 6 Performance tuning 7 Perceived performance 8 Performance Equation 9 See also 10 References Technical and nontechnical definitions edit The performance of any computer system can be evaluated in measurable technical terms using one or more of the metrics listed above This way the performance can be Compared relative to other systems or the same system beforeafter changes In absolute terms eg for fulfilling a contractual obligation Whilst the above definition relates to a scientific technical approach the following definition given by Arnold Allen would be useful for a nontechnical audience The word performance in computer performance means the same thing that performance means in other contexts that is it means How well is the computer doing the work it is supposed to do 1 As an aspect of software quality edit Computer software performance particularly software application response time is an aspect of software quality that is important in humancomputer interactions Performance engineering edit Performance engineering within systems engineering encompasses the set of roles skills activities practices tools and deliverables applied at every phase of the systems development life cycle which ensures that a solution will be designed implemented and operationally supported to meet the performance requirements defined for the solution Performance engineering continuously deals with tradeoffs between types of performance Occasionally a CPU designer can find a way to make a CPU with better overall performance by improving one of the aspects of performance presented below without sacrificing the CPUs performance in other areas For example building the CPU out of better faster transistors However sometimes pushing one type of performance to an extreme leads to a CPU with worse overall performance because other important aspects were sacrificed to get one impressivelooking number for example the chips clock rate see the megahertz myth Application performance engineering edit Main article Application performance engineering Application Performance Engineering APE is a specific methodology within performance engineering designed to meet the challenges associated with application performance in increasingly distributed mobile cloud and terrestrial IT environments It includes the roles skills activities practices tools and deliverables applied at every phase of the application lifecycle that ensure an application will be designed implemented and operationally supported to meet nonfunctional performance requirements Aspects of Performance edit Computer performance metrics things to measure include availability response time channel capacity latency completion time service time bandwidth throughput relative efficiency scalability performance per watt compression ratio instruction path length and speed up CPU benchmarks are available 2 Availability edit Main article Availability Availability of a system is typically measured as a factor of its reliability as reliability increases so does availability that is less downtime Availability of a system may also be increased by the strategy of focusing on increasing testability and maintainability and not on reliability Improving maintainability is generally easier than reliability Maintainability estimates Repair rates are also generally more accurate However because the uncertainties in the reliability estimates are in most cases very large it is likely to dominate the availability prediction uncertainty problem even while maintainability levels are very high Response time edit Main article Response time technology Response time is the total amount of time it takes to respond to a request for service In computing that service can be any unit of work from a simple disk IO to loading a complex web page The response time is the sum of three numbers 3 Service time How long it takes to do the work requested Wait time How long the request has to wait for requests queued ahead of it before it gets to run Transmission time How long it takes to move the request to the computer doing the work and the response back to the requestor Processing speed edit Main articles Instructions per second and FLOPS Most consumers pick a computer architecture normally Intel IA32 architecture to be able to run a large base of preexisting precompiled software Being relatively uninformed on computer benchmarks some of them pick a particular CPU based on operating frequency see megahertz myth Some system designers building parallel computers pick CPUs based on the speed per dollar Channel capacity edit Main article Channel capacity Channel capacity is the tightest upper bound on the rate of information that can be reliably transmitted over a communications channel By the noisychannel coding theorem the channel capacity of a given channel is the limiting information rate in units of information per unit time that can be achieved with arbitrarily small error probability 4 5 Information theory developed by Claude E Shannon during World War II defines the notion of channel capacity and provides a mathematical model by which one can compute it The key result states that the capacity of the channel as defined above is given by the maximum of the mutual information between the input and output of the channel where the maximization is with respect to the input distribution 6 Latency edit Main article Latency engineering Latency is a time delay between the cause and the effect of some physical change in the system being observed Latency is a result of the limited velocity with which any physical interaction can take place This velocity is always lower or equal to speed of light Therefore every physical system that has spatial dimensions different from zero will experience some sort of latency The precise definition of latency depends on the system being observed and the nature of stimulation In communications the lower limit of latency is determined by the medium being used for communications In reliable twoway communication systems latency limits the maximum rate that information can be transmitted as there is often a limit on the amount of information that is inflight at any one moment In the field of humanmachine interaction perceptible latency delay between what the user commands and when the computer provides the results has a strong effect on user satisfaction and usability Computers run sets of instructions called a process In operating systems the execution of the process can be postponed if other processes are also executing In addition the operating system can schedule when to perform the action that the process is commanding For example suppose a process commands that a computer cards voltage output be set highlowhighlow and so on at a rate of 1000Hz The operating system may choose to adjust the scheduling of each transition highlow or lowhigh based on an internal clock The latency is the delay between the process instruction commanding the transition and the hardware actually transitioning the voltage from high to low or low to high System designers building realtime computing systems want to guarantee worstcase response That is easier to do when the CPU has low interrupt latency and when it has deterministic response Bandwidth edit Main article Bandwidth computing In computer networking bandwidth is a measurement of bitrate of available or consumed data communication resources expressed in bits per second or multiples of it bits kbits Mbits Gbits etc Bandwidth sometimes defines the net bit rate aka peak bit rate information rate or physical layer useful bit rate channel capacity or the maximum throughput of a logical or physical communication path in a digital communication system For example bandwidth tests measure the maximum throughput of a computer network The reason for this usage is that according to Hartleys law the maximum data rate of a physical communication link is proportional to its bandwidth in hertz which is sometimes called frequency bandwidth spectral bandwidth RF bandwidth signal bandwidth or analog bandwidth Throughput edit Main article Throughput In general terms throughput is the rate of production or the rate at which something can be processed In communication networks throughput is essentially synonymous to digital bandwidth consumption In wireless networks or cellular communication networks the system spectral efficiency in bitsHzarea unit bitsHzsite or bitsHzcell is the maximum system throughput aggregate throughput divided by the analog bandwidth and some measure of the system coverage area In integrated circuits often a block in a data flow diagram has a single input and a single output and operate on discrete packets of information Examples of such blocks are FFT modules or binary multipliers Because the units of throughput are the reciprocal of the unit for propagation delay which is seconds per message or seconds per output throughput can be used to relate a computational device performing a dedicated function such as an ASIC or embedded processor to a communications channel simplifying system analysis Relative efficiency edit Main article Relative efficiency Scalability edit Main article Scalability Scalability is the ability of a system network or process to handle a growing amount of work in a capable manner or its ability to be enlarged to accommodate that growth Power consumption edit The amount of electricity used by the computer This becomes especially important for systems with limited power sources such as solar batteries human power Performance per watt edit Main article Performance per watt System designers building parallel computers such as Googles hardware pick CPUs based on their speed per watt of power because the cost of powering the CPU outweighs the cost of the CPU itself 7 Compression ratio edit Main article Data compression Compression is useful because it helps reduce resource usage such as data storage space or transmission capacity Because compressed data must be decompressed to use this extra processing imposes computational or other costs through decompression this situation is far from being a free lunch Data compression is subject to a spacetime complexity tradeoff Size and weight edit This is an important performance feature of mobile systems from the smart phones you keep in your pocket to the portable embedded systems in a spacecraft Environmental impact edit Further information Green computing The effect of a computer or computers on the environment during manufacturing and recycling as well as during use Measurements are taken with the objectives of reducing waste reducing hazardous materials and minimizing a computers ecological footprint Transistor count edit Main article Transistor count The transistor count is the number of transistors on an integrated circuit IC Transistor count is the most common measure of IC complexity Benchmarks edit Main article Benchmark computing Because there are so many programs to test a CPU on all aspects of performance benchmarks were developed The most famous benchmarks are the SPECint and SPECfp benchmarks developed by Standard Performance Evaluation Corporation and the Certification Mark benchmark developed by the Embedded Microprocessor Benchmark Consortium EEMBC Software performance testing edit Main article Software performance testing In software engineering performance testing is in general testing performed to determine how a system performs in terms of responsiveness and stability under a particular workload It can also serve to investigate measure validate or verify other quality attributes of the system such as scalability reliability and resource usage Performance testing is a subset of performance engineering an emerging computer science practice which strives to build performance into the implementation design and architecture of a system Profiling performance analysis edit Main article Profiling computer programming In software engineering profiling program profiling software profiling is a form of dynamic program analysis that measures for example the space memory or time complexity of a program the usage of particular instructions or frequency and duration of function calls The most common use of profiling information is to aid program optimization Profiling is achieved by instrumenting either the program source code or its binary executable form using a tool called a profiler or code profiler A number of different techniques may be used by profilers such as eventbased statistical instrumented and simulation methods Performance tuning edit Main article Performance tuning Performance tuning is the improvement of system performance This is typically a computer application but the same methods can be applied to economic markets bureaucracies or other complex systems The motivation for such activity is called a performance problem which can be real or anticipated Most systems will respond to increased load with some degree of decreasing performance A systems ability to accept a higher load is called scalability and modifying a system to handle a higher load is synonymous to performance tuning Systematic tuning follows these steps Assess the problem and establish numeric values that categorize acceptable behavior Measure the performance of the system before modification Identify the part of the system that is critical for improving the performance This is called the bottleneck Modify that part of the system to remove the bottleneck Measure the performance of the system after modification If the modification makes the performance better adopt it If the modification makes the performance worse put it back to the way it was Perceived performance edit Main article Perceived performance Perceived performance in computer engineering refers to how quickly a software feature appears to perform its task The concept applies mainly to user acceptance aspects The amount of time an application takes to start up or a file to download is not made faster by showing a startup screen see Splash screen or a file progress dialog box However it satisfies some human needs it appears faster to the user as well as providing a visual cue to let them know the system is handling their request In most cases increasing real performance increases perceived performance but when real performance cannot be increased due to physical limitations techniques can be used to increase perceived performance Performance Equation edit The total amount of time t required to execute a particular benchmark program is t N C f displaystyle ttfrac NCf or equivalently P I f N displaystyle Ptfrac IfN 8 where P 1 t textstyle Pfrac 1t is the performance in terms of timetoexecute N textstyle N is the number of instructions actually executed the instruction path length The code density of the instruction set strongly affects N The value of N can either be determined exactly by using an instruction set simulator if available or by estimationitself based partly on estimated or actual frequency distribution of input variables and by examining generated machine code from an HLL compiler It cannot be determined from the number of lines of HLL source code N is not affected by other processes running on the same processor The significant point here is that hardware normally does not keep track of or at least make easily available a value of N for executed programs The value can therefore only be accurately determined by instruction set simulation which is rarely practiced f textstyle f is the clock frequency in cycles per second C 1 I textstyle Cfrac 1I is the average cycles per instruction CPI for this benchmark I 1 C textstyle Ifrac 1C is the average instructions per cycle IPC for this benchmark Even on one machine a different compiler or the same compiler with different compiler optimization switches can change N and CPIthe benchmark executes faster if the new compiler can improve N or C without making the other worse but often there is a tradeoff between themis it better for example to use a few complicated instructions that take a long time to execute or to use instructions that execute very quickly although it takes more of them to execute the benchmark A CPU designer is often required to implement a particular instruction set and so cannot change NSometimes a designer focuses on improving performance by making significant improvements in f with techniques such as deeper pipelines and faster caches while hopefully not sacrificing too much Cleading to a speeddemon CPU designSometimes a designer focuses on improving performance by making significant improvements in CPI with techniques such as outoforder execution superscalar CPUs larger caches caches with improved hit rates improved branch prediction speculative execution etc while hopefully not sacrificing too much clock frequencyleading to a brainiac CPU design 9 For a given instruction set and therefore fixed N and semiconductor process the maximum singlethread performance 1t requires a balance between brainiac techniques and speedracer techniques 8 See also edit Algorithmic efficiency Computer performance by orders of magnitude Network performance Latency oriented processor architecture Optimization computer science RAM update rate Complete instruction set Hardware acceleration Speedup Cache replacement policies References edit Computer Performance Analysis with Mathematica by Arnold O Allen Academic Press 1994 11 Introduction pg 1 Measuring Program Similarity Experiments with SPEC CPU Benchmark Suites CiteSeerX 1011123501 mwparseroutput citecitationfontstyleinheritmwparseroutput citation qquotesmwparseroutput idlockfree amwparseroutput citation cs1lockfree abackgroundurluploadwikimediaorgwikipediacommonsthumb665Lockgreensvg9pxLockgreensvgpngnorepeatbackgroundpositionright 1em centermwparseroutput idlocklimited amwparseroutput idlockregistration amwparseroutput citation cs1locklimited amwparseroutput citation cs1lockregistration abackgroundurluploadwikimediaorgwikipediacommonsthumbdd6Lockgrayalt2svg9pxLockgrayalt2svgpngnorepeatbackgroundpositionright 1em centermwparseroutput idlocksubscription amwparseroutput citation cs1locksubscription abackgroundurluploadwikimediaorgwikipediacommonsthumbaaaLockredalt2svg9pxLockredalt2svgpngnorepeatbackgroundpositionright 1em centermwparseroutput cs1subscriptionmwparseroutput cs1registrationcolor555mwparseroutput cs1subscription spanmwparseroutput cs1registration spanborderbottom1px dottedcursorhelpmwparseroutput cs1wsicon abackgroundurluploadwikimediaorgwikipediacommonsthumb44cWikisourcelogosvg12pxWikisourcelogosvgpngnorepeatbackgroundpositionright 1em centermwparseroutput codecs1codecolorinheritbackgroundinheritborderinheritpaddinginheritmwparseroutput cs1hiddenerrordisplaynonefontsize100mwparseroutput cs1visibleerrorfontsize100mwparseroutput cs1maintdisplaynonecolor33aa33marginleft03emmwparseroutput cs1subscriptionmwparseroutput cs1registrationmwparseroutput cs1formatfontsize95mwparseroutput cs1kernleftmwparseroutput cs1kernwlleftpaddingleft02emmwparseroutput cs1kernrightmwparseroutput cs1kernwlrightpaddingright02em Wescott Bob 2013 The Every Computer Performance Book Chapter 3 Useful laws CreateSpace ISBN 1482657759 Saleem Bhatti Channel capacity Lecture notes for MSc Data Communication Networks and Distributed Systems D51 Basic Communications and Networks Archived from the original on 20070821 Jim Lesurf Signals look like noise Information and Measurement 2nd ed Thomas M Cover Joy A Thomas 2006 Elements of Information Theory John Wiley Sons New York Archived copy Archived from the original on 20050327 Retrieved 20090121 CS1 maint archived copy as title link 1 a b Paul DeMoneThe Incredible Shrinking CPU2004 2 Brainiacs Speed Demons and Farewell by Linley Gwennap 