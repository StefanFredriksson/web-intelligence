AI winter This article needs to be updated Please update this article to reflect recent events or newly available information April 2019 Artificial intelligence Major goals Knowledge reasoning Planning Machine learning Natural language processing Computer vision Robotics Artificial general intelligence Approaches Symbolic Deep learning Bayesian networks Evolutionary algorithms Philosophy Ethics Existential risk Turing test Chinese room Control problem Friendly AI History Timeline Progress AI winter Technology Applications Projects Programming languages Glossary Glossary v t e In the history of artificial intelligence an AI winter is a period of reduced funding and interest in artificial intelligence research 1 The term was coined by analogy to the idea of a nuclear winter 2 The field has experienced several hype cycles followed by disappointment and criticism followed by funding cuts followed by renewed interest years or decades later The term first appeared in 1984 as the topic of a public debate at the annual meeting of AAAI then called the American Association of Artificial Intelligence It is a chain reaction that begins with pessimism in the AI community followed by pessimism in the press followed by a severe cutback in funding followed by the end of serious research 2 At the meeting Roger Schank and Marvin Minsky two leading AI researchers who had survived the winter of the 1970swarned the business community that enthusiasm for AI had spiraled out of control in the 1980s and that disappointment would certainly follow Three years later the billiondollar AI industry began to collapse 2 Hype is common in many emerging technologies such as the railway mania or the dotcom bubble The AI winter was a result of such hype due to overinflated promises by developers unnaturally high expectations from endusers and extensive promotion in the media 3 Despite the rise and fall of AIs reputation it has continued to develop new and successful technologies AI researcher Rodney Brooks would complain in 2002 that theres this stupid myth out there that AI has failed but AI is around you every second of the day 4 In 2005 Ray Kurzweil agreed Many observers still think that the AI winter was the end of the story and that nothing since has come of the AI field Yet today many thousands of AI applications are deeply embedded in the infrastructure of every industry 5 Enthusiasm and optimism about AI has increased since its low point in the early 1990s Beginning about 2012 interest in artificial intelligence and especially the subfield of machine learning from the research and corporate communities led to a dramatic increase in funding and investment Contents 1 Overview 2 Early episodes 21 Machine translation and the ALPAC report of 1966 22 The abandonment of connectionism in 1969 3 The setbacks of 1974 31 The Lighthill report 32 DARPAs early 1970s funding cuts 33 The SUR debacle 4 The setbacks of the late 1980s and early 1990s 41 The 1987 collapse of the LISP machine market 42 Slowdown in deployment of expert systems 43 The end of the Fifth Generation project 44 Strategic Computing Initiative cutbacks 5 Developments postAI winter 51 AI integration 52 AI funding 53 Current AI spring 6 Underlying causes behind AI winters 61 Hype 62 Institutional factors 63 Economic factors 64 Insufficient computing capability 65 Empty pipeline 66 Failure to adapt 7 Arguments and debates on past and future of AI 8 See also 9 Notes 10 References 11 Further reading 12 External links Overview edit There were two major winters in 19741980 and 19871993 6 and several smaller episodes including the following 1966 failure of machine translation 1970 abandonment of connectionism Period of overlapping trends 197175 DARPA s frustration with the Speech Understanding Research program at Carnegie Mellon University 1973 large decrease in AI research in the United Kingdom in response to the Lighthill report 197374 DARPAs cutbacks to academic AI research in general 1987 collapse of the LISP machine market 1988 cancellation of new spending on AI by the Strategic Computing Initiative 1993 resistance to new expert systems deployment and maintenance 1990s end of the Fifth Generation computer projects original goals Early episodes edit Machine translation and the ALPAC report of 1966 edit See also History of machine translation During the Cold War the US government was particularly interested in the automatic instant translation of Russian documents and scientific reports The government aggressively supported efforts at machine translation starting in 1954 At the outset the researchers were optimistic Noam Chomsky s new work in grammar was streamlining the translation process and there were many predictions of imminent breakthroughs 7 Briefing for US Vice President Gerald Ford in 1973 on the junctiongrammar based computer translation model However researchers had underestimated the profound difficulty of wordsense disambiguation In order to translate a sentence a machine needed to have some idea what the sentence was about otherwise it made mistakes An apocryphal 8 example is the spirit is willing but the flesh is weak Translated back and forth with Russian it became the vodka is good but the meat is rotten 9 Similarly out of sight out of mind became blind idiot Later researchers would call this the commonsense knowledge problem By 1964 the National Research Council had become concerned about the lack of progress and formed the Automatic Language Processing Advisory Committee ALPAC to look into the problem They concluded in a famous 1966 report that machine translation was more expensive less accurate and slower than human translation After spending some 20 million dollars the NRC ended all support Careers were destroyed and research ended 2 7 Machine translation is still an open research problem in the 21st century which has been met with some success Google Translate Yahoo Babel Fish The abandonment of connectionism in 1969 edit See also Perceptrons and Frank Rosenblatt Some of the earliest work in AI used networks or circuits of connected units to simulate intelligent behavior Examples of this kind of work called connectionism include Walter Pitts and Warren McCullough s first description of a neural network for logic and Marvin Minsky s work on the SNARC system In the late 1950s most of these approaches were abandoned when researchers began to explore symbolic reasoning as the essence of intelligence following the success of programs like the Logic Theorist and the General Problem Solver 10 However one type of connectionist work continued the study of perceptrons invented by Frank Rosenblatt who kept the field alive with his salesmanship and the sheer force of his personality 11 He optimistically predicted that the perceptron may eventually be able to learn make decisions and translate languages 12 Mainstream research into perceptrons came to an abrupt end in 1969 when Marvin Minsky and Seymour Papert published the book Perceptrons which was perceived as outlining the limits of what perceptrons could do Connectionist approaches were abandoned for the next decade or so While important work such as Paul Werbos discovery of backpropagation continued in a limited way major funding for connectionist projects was difficult to find in the 1970s and early 1980s 13 The winter of connectionist research came to an end in the middle 1980s when the work of John Hopfield David Rumelhart and others revived large scale interest in neural networks 14 Rosenblatt did not live to see this however as he died in a boating accident shortly after Perceptrons was published 12 The setbacks of 1974 edit The Lighthill report edit See also Lighthill report In 1973 professor Sir James Lighthill was asked by the UK Parliament to evaluate the state of AI research in the United Kingdom His report now called the Lighthill report criticized the utter failure of AI to achieve its grandiose objectives He concluded that nothing being done in AI couldnt be done in other sciences He specifically mentioned the problem of combinatorial explosion or intractability which implied that many of AIs most successful algorithms would grind to a halt on real world problems and were only suitable for solving toy versions 15 The report was contested in a debate broadcast in the BBC Controversy series in 1973 The debate The general purpose robot is a mirage from the Royal Institution was Lighthill versus the team of Donald Michie John McCarthy and Richard Gregory 16 McCarthy later wrote that the combinatorial explosion problem has been recognized in AI from the beginning 17 The report led to the complete dismantling of AI research in England 15 AI research continued in only a few universities Edinburgh Essex and Sussex This created a bowwave effect that led to funding cuts across Europe writes James Hendler 18 Research would not revive on a large scale until 1983 when Alvey a research project of the British Government began to fund AI again from a war chest of 350 million in response to the Japanese Fifth Generation Project see below Alvey had a number of UKonly requirements which did not sit well internationally especially with US partners and lost Phase 2 funding DARPAs early 1970s funding cuts edit During the 1960s the Defense Advanced Research Projects Agency then known as ARPA now known as DARPA provided millions of dollars for AI research with almost no strings attached DARPAs director in those years J C R Licklider believed in funding people not projects 19 and allowed AIs leaders such as Marvin Minsky John McCarthy Herbert A Simon or Allen Newell to spend it almost any way they liked This attitude changed after the passage of Mansfield Amendment in 1969 which required DARPA to fund missionoriented direct research rather than basic undirected research 20 Pure undirected research of the kind that had gone on in the 1960s would no longer be funded by DARPA Researchers now had to show that their work would soon produce some useful military technology AI research proposals were held to a very high standard The situation was not helped when the Lighthill report and DARPAs own study the American Study Group suggested that most AI research was unlikely to produce anything truly useful in the foreseeable future DARPAs money was directed at specific projects with identifiable goals such as autonomous tanks and battle management systems By 1974 funding for AI projects was hard to find 20 AI researcher Hans Moravec blamed the crisis on the unrealistic predictions of his colleagues Many researchers were caught up in a web of increasing exaggeration Their initial promises to DARPA had been much too optimistic Of course what they delivered stopped considerably short of that But they felt they couldnt in their next proposal promise less than in the first one so they promised more 21 The result Moravec claims is that some of the staff at DARPA had lost patience with AI research It was literally phrased at DARPA that some of these people were going to be taught a lesson by having their twomilliondollarayear contracts cut to almost nothing Moravec told Daniel Crevier 22 While the autonomous tank project was a failure the battle management system the Dynamic Analysis and Replanning Tool proved to be enormously successful saving billions in the first Gulf War repaying all of DARPAs investment in AI 23 and justifying DARPAs pragmatic policy 24 The SUR debacle edit DARPA was deeply disappointed with researchers working on the Speech Understanding Research program at Carnegie Mellon University DARPA had hoped for and felt it had been promised a system that could respond to voice commands from a pilot The SUR team had developed a system which could recognize spoken English but only if the words were spoken in a particular order DARPA felt it had been duped and in 1974 they cancelled a three million dollar a year grant 25 Many years later several successful commercial speech recognition systems would use the technology developed by the Carnegie Mellon team such as hidden Markov models and the market for speech recognition systems would reach 4 billion by 2001 26 The setbacks of the late 1980s and early 1990s edit The 1987 collapse of the LISP machine market edit In the 1980s a form of AI program called an expert system was adopted by corporations around the world The first commercial expert system was XCON developed at Carnegie Mellon for Digital Equipment Corporation and it was an enormous success it was estimated to have saved the company 40 million dollars over just six years of operation Corporations around the world began to develop and deploy expert systems and by 1985 they were spending over a billion dollars on AI most of it to inhouse AI departments An industry grew up to support them including software companies like Teknowledge and Intellicorp KEE and hardware companies like Symbolics and LISP Machines Inc who built specialized computers called LISP machines that were optimized to process the programming language LISP the preferred language for AI 27 28 In 1987 three years after Minsky and Schanks prediction the market for specialized AI hardware collapsed Workstations by companies like Sun Microsystems offered a powerful alternative to LISP machines and companies like Lucid offered a LISP environment for this new class of workstations The performance of these general workstations became an increasingly difficult challenge for LISP Machines Companies like Lucid and Franz LISP offered increasingly more powerful versions of LISP For example benchmarks were published showing workstations maintaining a performance advantage over LISP machines 29 Later desktop computers built by Apple and IBM would also offer a simpler and more popular architecture to run LISP applications on By 1987 they had become more powerful than the more expensive LISP machines The desktop computers had rulebased engines such as CLIPS available 30 These alternatives left consumers with no reason to buy an expensive machine specialized for running LISP An entire industry worth half a billion dollars was replaced in a single year 31 Commercially many LISP companies failed like Symbolics LISP Machines Inc Lucid Inc etc Other companies like Texas Instruments and Xerox abandoned the field However a number of customer companies that is companies using systems written in LISP and developed on LISP machine platforms continued to maintain systems In some cases this maintenance involved the assumption of the resulting support work 3 Slowdown in deployment of expert systems edit By the early 1990s the earliest successful expert systems such as XCON proved too expensive to maintain They were difficult to update they could not learn they were brittle ie they could make grotesque mistakes when given unusual inputs and they fell prey to problems such as the qualification problem that had been identified years earlier in research in nonmonotonic logic Expert systems proved useful but only in a few special contexts 32 33 Another problem dealt with the computational hardness of truth maintenance efforts for general knowledge KEE used an assumptionbased approach see NASA TEXSYS supporting multipleworld scenarios that was difficult to understand and apply The few remaining expert system shell companies were eventually forced to downsize and search for new markets and software paradigms like casebased reasoning or universal database access The maturation of Common Lisp saved many systems such as ICAD which found application in knowledgebased engineering Other systems such as Intellicorps KEE moved from LISP to a C variant on the PC and helped establish objectoriented technology including providing major support for the development of UML see UML Partners The end of the Fifth Generation project edit See also Fifth generation computer In 1981 the Japanese Ministry of International Trade and Industry set aside 850 million for the Fifth Generation computer project Their objectives were to write programs and build machines that could carry on conversations translate languages interpret pictures and reason like human beings By 1991 the impressive list of goals penned in 1981 had not been met Indeed some of them had not been met in 2001 or 2011 As with other AI projects expectations had run much higher than what was actually possible 34 35 Strategic Computing Initiative cutbacks edit See also Strategic Computing Initiative In 1983 in response to the fifth generation project DARPA again began to fund AI research through the Strategic Computing Initiative As originally proposed the project would begin with practical achievable goals which even included artificial general intelligence as long term objective The program was under the direction of the Information Processing Technology Office IPTO and was also directed at supercomputing and microelectronics By 1985 it had spent 100 million and 92 projects were underway at 60 institutions half in industry half in universities and government labs AI research was generously funded by the SCI 36 Jack Schwarz who ascended to the leadership of IPTO in 1987 dismissed expert systems as clever programming and cut funding to AI deeply and brutally eviscerating SCI Schwarz felt that DARPA should focus its funding only on those technologies which showed the most promise in his words DARPA should surf rather than dog paddle and he felt strongly AI was not the next wave Insiders in the program cited problems in communication organization and integration A few projects survived the funding cuts including pilots assistant and an autonomous land vehicle which were never delivered and the DART battle management system which as noted above was successful 37 Developments postAI winter edit This section needs to be updated Please update this article to reflect recent events or newly available information September 2015 A survey of reports from the early 2000s suggests that AIs reputation was still less than stellar Alex Castro quoted in The Economist 7 June 2007 Investors were put off by the term voice recognition which like artificial intelligence is associated with systems that have all too often failed to live up to their promises 38 Patty Tascarella in Pittsburgh Business Times 2006 Some believe the word robotics actually carries a stigma that hurts a companys chances at funding 39 John Markoff in the New York Times 2005 At its low point some computer scientists and software engineers avoided the term artificial intelligence for fear of being viewed as wildeyed dreamers 40 Many researchers in AI in the mid 2000s deliberately called their work by other names such as informatics machine learning analytics knowledgebased systems business rules management cognitive systems intelligent systems intelligent agents or computational intelligence to indicate that their work emphasizes particular tools or is directed at a particular subproblem Although this may be partly because they consider their field to be fundamentally different from AI it is also true that the new names help to procure funding by avoiding the stigma of false promises attached to the name artificial intelligence 40 41 AI integration edit In the late 1990s and early 21st century AI technology became widely used as elements of larger systems 42 5 but the field is rarely credited for these successes In 2006 Nick Bostrom explained that a lot of cutting edge AI has filtered into general applications often without being called AI because once something becomes useful enough and common enough its not labeled AI anymore 43 Rodney Brooks stated around the same time that theres this stupid myth out there that AI has failed but AI is around you every second of the day 4 Technologies developed by AI researchers have achieved commercial success in a number of domains such as machine translation data mining industrial robotics logistics 44 speech recognition 45 banking software 46 medical diagnosis 46 and Google s search engine 47 Fuzzy logic controllers have been developed for automatic gearboxes in automobiles the 2006 Audi TT VW Touareg 48 and VW Caravell feature the DSP transmission which utilizes fuzzy logic a number of Škoda variants Škoda Fabia also currently include a fuzzy logicbased controller Camera sensors widely utilize fuzzy logic to enable focus Heuristic search and data analytics are both technologies that have developed from the evolutionary computing and machine learning subdivision of the AI research community Again these techniques have been applied to a wide range of real world problems with considerable commercial success Data analytics technology utilizing algorithms for the automated formation of classifiers that were developed in the supervised machine learning community in the 1990s for example TDIDT Support Vector Machines Neural Nets IBL are now when used pervasively by companies for marketing survey targeting and discovery of trends and features in data sets AI funding edit Researchers and economists frequently judged the status of an AI winter by reviewing which AI projects were being funded how much and by whom Trends in funding are often set by major funding agencies in the developed world Currently DARPA and a civilian funding program called EUFP7 provide much of the funding for AI research in the US and European Union As of 2007 DARPA was soliciting AI research proposals under a number of programs including The Grand Challenge Program Cognitive Technology Threat Warning System CT2WS Human Assisted Neural Devices SN0743 Autonomous RealTime Ground Ubiquitous SurveillanceImaging System ARGUSIS and Urban Reasoning and Geospatial Exploitation Technology URGENT Perhaps best known is DARPAs Grand Challenge Program 49 which has developed fully automated road vehicles that can successfully navigate real world terrain 50 in a fully autonomous fashion DARPA has also supported programs on the Semantic Web with a great deal of emphasis on intelligent management of content and automated understanding However James Hendler the manager of the DARPA program at the time expressed some disappointment with the governments ability to create rapid change and moved to working with the World Wide Web Consortium to transition the technologies to the private sector The EUFP7 funding program provides financial support to researchers within the European Union In 20072008 it was funding AI research under the Cognitive Systems Interaction and Robotics Programme 193m the Digital Libraries and Content Programme 203m and the FET programme 185m 51 Current AI spring edit A marked increase in AI funding development deployment and commercial use has led to the idea of the AI winter being long over 52 Concerns are occasionally raised that a new AI winter could be triggered by any overly ambitious or unrealistic promise by prominent AI scientists or overpromising on the part of commercial vendors Underlying causes behind AI winters edit Several explanations have been put forth for the cause of AI winters in general As AI progressed from governmentfunded applications to commercial ones new dynamics came into play While hype is the most commonly cited cause the explanations are not necessarily mutually exclusive Hype edit This section possibly contains original research Please improve it by verifying the claims made and adding inline citations Statements consisting only of original research should be removed March 2015 Learn how and when to remove this template message The AI winters can citation needed be partly understood as a sequence of overinflated expectations and subsequent crash seen in stockmarkets and exemplified citation needed by the railway mania and dotcom bubble In a common pattern in development of new technology known as hype cycle an event typically a technological breakthrough creates publicity which feeds on itself to create a peak of inflated expectations followed by a trough of disillusionment Since scientific and technological progress cant keep pace with the publicityfueled increase in expectations among investors and other stakeholders a crash must follow AI technology seems to be no exception to this rule citation needed Institutional factors edit Another factor is AIs place in the organisation of universities Research on AI often takes the form of interdisciplinary research AI is therefore prone to the same problems other types of interdisciplinary research face Funding is channeled through the established departments and during budget cuts there will be a tendency to shield the core contents of each department at the expense of interdisciplinary and less traditional research projects Economic factors edit Downturns in a countrys national economy cause budget cuts in universities The core contents tendency worsen the effect on AI research and investors in the market are likely to put their money into less risky ventures during a crisis Together this may amplify an economic downturn into an AI winter It is worth noting that the Lighthill report came at a time of economic crisis in the UK 53 when universities had to make cuts and the question was only which programs should go Insufficient computing capability edit Early in the computing history the potential for neural networks was understood but it has never been realized Fairly simple networks require significant computing capacity even by todays standards Empty pipeline edit It is common to see the relationship between basic research and technology as a pipeline Advances in basic research give birth to advances in applied research which in turn leads to new commercial applications From this it is often argued that a lack of basic research will lead to a drop in marketable technology some years down the line This view was advanced by James Hendler in 2008 30 when he claimed that the fall of expert systems in the late 80s was not due to an inherent and unavoidable brittleness of expert systems but to funding cuts in basic research in the 1970s These expert systems advanced in the 1980s through applied research and product development but by the end of the decade the pipeline had run dry and expert systems were unable to produce improvements that could have overcome this brittleness and secured further funding Failure to adapt edit The fall of the LISP machine market and the failure of the fifth generation computers were cases of expensive advanced products being overtaken by simpler and cheaper alternatives This fits the definition of a lowend disruptive technology with the LISP machine makers being marginalized Expert systems were carried over to the new desktop computers by for instance CLIPS so the fall of the LISP machine market and the fall of expert systems are strictly speaking two separate events Still the failure to adapt to such a change in the outside computing milieu is cited as one reason for the 1980s AI winter 30 Arguments and debates on past and future of AI edit Several philosophers cognitive scientists and computer scientists have speculated on where AI might have failed and what lies in its future Hubert Dreyfus highlighted flawed assumptions of AI research in the past and as early as 1966 correctly predicted that the first wave of AI research would fail to fulfill the very public promises it was making Other critics like Noam Chomsky have argued that AI is headed in the wrong direction in part because of its heavy reliance on statistical techniques 54 Chomskys comments fit into a larger debate with Peter Norvig centered around the role of statistical methods in AI The exchange between the two started with comments made by Chomsky at a symposium at MIT 55 to which Norvig wrote a response 56 See also edit AI effect History of artificial intelligence Software crisis Notes edit AI Expert Newsletter W is for Winter Archived 9 November 2013 at the Wayback Machine a b c d Crevier 1993 p203 a b The Brain Makers Genius Ego And Greed In The Quest For Machines That Think New York MacmillanSAMS 1994 ISBN 9780988593718 mwparseroutput citecitationfontstyleinheritmwparseroutput citation qquotesmwparseroutput idlockfree amwparseroutput citation cs1lockfree abackgroundurluploadwikimediaorgwikipediacommonsthumb665Lockgreensvg9pxLockgreensvgpngnorepeatbackgroundpositionright 1em centermwparseroutput idlocklimited amwparseroutput idlockregistration amwparseroutput citation cs1locklimited amwparseroutput citation cs1lockregistration abackgroundurluploadwikimediaorgwikipediacommonsthumbdd6Lockgrayalt2svg9pxLockgrayalt2svgpngnorepeatbackgroundpositionright 1em centermwparseroutput idlocksubscription amwparseroutput citation cs1locksubscription abackgroundurluploadwikimediaorgwikipediacommonsthumbaaaLockredalt2svg9pxLockredalt2svgpngnorepeatbackgroundpositionright 1em centermwparseroutput cs1subscriptionmwparseroutput cs1registrationcolor555mwparseroutput cs1subscription spanmwparseroutput cs1registration spanborderbottom1px dottedcursorhelpmwparseroutput cs1wsicon abackgroundurluploadwikimediaorgwikipediacommonsthumb44cWikisourcelogosvg12pxWikisourcelogosvgpngnorepeatbackgroundpositionright 1em centermwparseroutput codecs1codecolorinheritbackgroundinheritborderinheritpaddinginheritmwparseroutput cs1hiddenerrordisplaynonefontsize100mwparseroutput cs1visibleerrorfontsize100mwparseroutput cs1maintdisplaynonecolor33aa33marginleft03emmwparseroutput cs1subscriptionmwparseroutput cs1registrationmwparseroutput cs1formatfontsize95mwparseroutput cs1kernleftmwparseroutput cs1kernwlleftpaddingleft02emmwparseroutput cs1kernrightmwparseroutput cs1kernwlrightpaddingright02em a b Kurzweil 2005 p263 a b Kurzweil 2005 p264 Different sources use different dates for the AI winter Consider 1 Howe 1994 Lighthills 1973 report provoked a massive loss of confidence in AI by the academic establishment in the UK and to a lesser extent in the US It persisted for a decade the socalled AI Winter 2 Russell Norvig 2003 p24 Overall the AI industry boomed from a few million dollars in 1980 to billions of dollars in 1988 Soon after that came a period called the AI Winter a b John Hutchins 2005 The history of machine translation in a nutshell Hutchins John 1995 The whisky was invisible or Persistent myths of MT Retrieved from httpwwwhutchinswebmeukMTNI111995pdf Russell Norvig 2003 p21 McCorduck 2004 pp52107 Pamela McCorduck quotes one colleague as saying He was a press agents dream a real medicine man McCorduck 2004 p105 a b Crevier 1993 pp1025 Crevier 1993 pp102105 McCorduck 2004 pp104107 Russell Norvig 2003 p22 Crevier 1993 pp2146 and Russell Norvig 2003 p25 a b Crevier 1993 p117 Russell Norvig 2003 p22 Howe 1994 and see also Lighthill 1973 BBC Controversy Lighthill debate 1973 BBC Controversy debates series ARTIFICIALINTELLIGENCEAPPLICATIONSINSTITUTE 1973 Retrieved 13 August 2010 McCarthy John 1993 Review of the Lighthill Report Archived from the original on 30 September 2008 Retrieved 10 September 2008 Hendler James Avoiding Another AI Winter PDF Archived from the original PDF on 12 February 2012 Crevier 1993 p65 a b NRC 1999 under Shift to Applied Research Increases Investment only the sections before 1980 apply to the current discussion Crevier 1993 p115 Crevier 1993 p117 Russell Norvig 2003 p25 NRC 1999 Crevier 1993 pp115116 on whom this account is based Other views include McCorduck 2004 pp306313 and NRC 1999 under Success in Speech Recognition NRC 1999 under Success in Speech Recognition Newquist 1994 pp189201 Crevier 1993 pp1612 197203 Brooks Rodney Design of an Optimizing Dynamically Retargetable Compiler for Common LISP PDF Lucid Inc Archived from the original PDF on 20 August 2013 a b c Avoiding another AI Winter James Hendler IEEE Intelligent Systems MarchApril 2008 Vol 23 No 2 pp 24 Crevier 1993 pp209210 Newquist 1994 p296 Crevier 1993 pp204208 Newquist 1994 pp431434 Crevier 1993 pp211212 McCorduck 2004 pp426429 McCorduck 2004 pp430431 Alex Castro in Are you talking to me The Economist Technology Quarterly 7 June 2007 Archived 13 June 2008 at the Wayback Machine Robotics firms find fundraising struggle with venture capital shy By Patty Tascarella Pittsburgh Business Times 11 August 2006 Archived 26 March 2014 at the Wayback Machine a b Markoff John 14 October 2005 Behind Artificial Intelligence a Squadron of Bright Real People The New York Times Retrieved 30 July 2007 Newquist 1994 p423 NRC 1999 under Artificial Intelligence in the 90s AI set to exceed human brain power CNNcom 26 July 2006 Archived 3 November 2006 at the Wayback Machine Russell Norvig 2003 p28 For the new state of the art in AIbased speech recognition see Are You Talking to Me Archived 13 June 2008 at the Wayback Machine a b AIinspired systems were already integral to many everyday technologies such as internet search engines bank software for processing transactions and in medical diagnosis Nick Bostrom AI set to exceed human brain power CNNcom 26 July 2006 Archived 3 November 2006 at the Wayback Machine For the use of AI at Google see Googles man behind the curtain Google backs character recognition and Spying an intelligent search engine Touareg Short Lead Press Introduction Volkswagen of America Archived 16 February 2012 at the Wayback Machine Grand Challenge Home Archived 24 December 2010 at the Wayback Machine DARPA Archived 6 March 2009 at the Wayback Machine Information and Communication Technologies in FP7 permanent dead link overview document for European Union funding Retrieved 20 September 2007 Newquist HP 2018 The Brain Makers Second Edition New York NY The Relayer Group p491 httpswwwtheguardiancomobituariesstory0212242400html obituary of Donald Michie in The Guardian Archived 27 January 2008 at the Wayback Machine Yarden Katz Noam Chomsky on Where Artificial Intelligence Went Wrong The Atlantic 1 November 2012 Archived 3 November 2012 at the Wayback Machine Noam Chomsky PinkerChomsky QA from MIT150 Panel Archived 17 May 2013 at the Wayback Machine Peter Norvig On Chomsky and the Two Cultures of Statistical Learning Archived 27 May 2011 at the Wayback Machine References edit Crevier Daniel 1993 AI The Tumultuous Search for Artificial Intelligence New York NY BasicBooks ISBN 0465029973 Hendler James 2007 Where Are All the Intelligent Agents IEEE Intelligent Systems 22 3 23 doi 101109MIS200762 Howe J November 1994 Artificial Intelligence at Edinburgh University a Perspective Archived from the original on 17 August 2007 Retrieved 30 August 2007 Kaplan Andreas Haenlein Michael 2018 Siri Siri in my Hand whos the Fairest in the Land On the Interpretations Illustrations and Implications of Artificial Intelligence Business Horizons Business Horizons 621 62 1525 doi 101016jbushor201808004 Kurzweil Ray 2005 The Singularity is Near Viking Press Cite journal requires journal help Lighthill Professor Sir James 1973 Artificial Intelligence A General Survey Artificial Intelligence a paper symposium Science Research Council Minsky Marvin Papert Seymour 1969 Perceptrons An Introduction to Computational Geometry The MIT Press Cite journal requires journal help McCorduck Pamela 2004 Machines Who Think 2nd ed Natick MA A K Peters Ltd ISBN 1568812051 NRC 1999 Developments in Artificial Intelligence Funding a Revolution Government Support for Computing Research National Academy Press Archived from the original on 12 January 2008 Retrieved 30 August 2007 CS1 maint BOT originalurl status unknown link Newquist HP 1994 The Brain Makers Genius Ego and Greed In The Search For Machines That Think MacmillanSAMS ISBN 9780988593718 Russell Stuart J Norvig Peter 2003 Artificial Intelligence A Modern Approach 2nd ed Upper Saddle River New Jersey Prentice Hall ISBN 0137903952 Further reading edit Marcus Gary Am I Human Researchers need new ways to distinguish artificial intelligence from the natural kind Scientific American vol 316 no 3 March 2017 pp 5863 Multiple tests of artificialintelligence efficacy are needed because just as there is no single test of athletic prowess there cannot be one ultimate test of intelligence One such test a Construction Challenge would test perception and physical actiontwo important elements of intelligent behavior that were entirely absent from the original Turing test Another proposal has been to give machines the same standardized tests of science and other disciplines that schoolchildren take A so far insuperable stumbling block to artificial intelligence is an incapacity for reliable disambiguation Virtually every sentence that people generate is ambiguous often in multiple ways A prominent example is known as the pronoun disambiguation problem a machine has no way of determining to whom or what a pronoun in a sentencesuch as he she or itrefers Luke Muehlhauser September 2016 What should we learn from past AI forecasts Open Philanthropy Project External links edit ComputerWorld article February 2005 AI Expert Newsletter January 2005 If It Works Its Not AI A Commercial Look at Artificial Intelligence startups Patterns of Software a collection of essays by Richard P Gabriel including several autobiographical essays Review of Artificial Intelligence A General Survey by John McCarthy Other Freddy II Robot Resources Includes a link to the 90minute 1973 Controversy debate from the Royal Academy of Lighthill vs Michie McCarthy and Gregory in response to Lighthills report to the British government v t e Financial bubbles Commodity booms Credit cycle Diamond rush Gold rush Irrational exuberance Oil boom Real estate bubble Stock market bubble 10001760 Tulip mania 16341637 Mississippi bubble 16841720 Brazilian Gold Rush c 16901760 South Sea bubble 17111720 17601840 Brazilian Gold Rush 17601840 Canal Mania c 1790c 1810 Carolina Gold Rush 18021825 1810s Alabama real estate bubble Georgia Gold Rush 1828c 1840 1830s Chicago real estate bubble Chilean silver rush 18301840 1840 1870 Chilean silver rush 18401850 Railway Mania c 1840c 1850 Brazilian Gold Rush 18401870 California Gold Rush 18481855 Queen Charlottes Gold Rush 1851 Victorian gold rush 1851c 1870 New South Wales gold rush 18511880 Australian gold rushes 18511914 Fraser Canyon Gold Rush 1858 Pikes Peak Gold Rush 18581861 Rock Creek Gold Rush 1859 Pennsylvania oil rush 18591891 Similkameen Gold Rush 1860 Stikine Gold Rush 1861 Colorado River mining boom 18611864 Otago Gold Rush 18611864 Cariboo Gold Rush 18611867 First Nova Scotia Gold Rush 18611874 Wild Horse Creek Gold Rush 18641865 Leechtown Gold Rush 18641865 West Coast Gold Rush 18641867 Big Bend Gold Rush c 1865 Vermilion Lake Gold Rush 18651867 Kildonan Gold Rush 1869 Omineca Gold Rush 1869 18701914 1870s Lapland gold rush Coromandel Gold Rushes c 1870c 1890 Cassiar Gold Rush c 1870c 1890 Brazilian Gold Rush 1870c 1900 Black Hills Gold Rush 18741880 Colorado Silver Boom 18791893 Western Australian gold rushes c 1880c 1900 Indiana gas boom c 18801903 Ohio oil rush c 1880c 1930 Tierra del Fuego gold rush 18831906 Cayoosh Gold Rush 1884 Witwatersrand Gold Rush 1886 Encilhamento 18861890 Cripple Creek Gold Rush c 1890c 1910 Klondike Gold Rush 18961899 Second Nova Scotia Gold Rush 18961903 Kobuk River Stampede 18971899 Mount Baker Gold Rush 1897c 1925 Nome Gold Rush 18991909 Fairbanks Gold Rush c 19001918 Texas oil boom 19011918 Cobalt silver rush 19031918 Porcupine Gold Rush 19091918 19181939 1920s Florida land boom c 19201925 Fairbanks Gold Rush 1918c 1930 Texas oil boom 19181945 Cobalt silver rush 1918c 1930 Porcupine Gold Rush 19181945 1930s Kakamega gold rush Third Nova Scotia Gold Rush 19321942 19451973 Texas oil boom 1945c 1950 Porcupine Gold Rush 1945c 1960 Poseidon bubble 19691970 1973 1982 Mexican oil boom 19771981 Silver Thursday 1980 New Zealand property bubble c 19801982 19822007 1980s oil glut New Zealand property bubble 1982 Spanish property bubble 19852008 Japanese asset price bubble 19861990 Dotcom bubble 19952000 Baltic states housing bubble 20002006 Irish property bubble c 20002007 2000s commodities boom 20002008 2000s Danish property bubble 20012006 Indian property bubble 20012007 United States housing bubble 20022006 Romanian property bubble 20022007 Polish property bubble 20022008 Canadian property bubble 20032008 Chinese property bubble 200511 Lebanese housing bubble 20052008 Bulgarian property bubble 20062008 North Dakota oil boom 20062008 Chinese stock bubble of 2007 Uranium bubble of 2007 Post 2008 North Dakota oil boom 20082012 2000s commodities boom 20082014 Canadian property bubble 20082019 Lebanese housing bubble 2008 Australian property bubble 2010 Cryptocurrency bubble 2011 AI winter Carbon bubble Chaotic bubble The Green Bubble Social media bubble Unicorn bubble US higher education bubble 